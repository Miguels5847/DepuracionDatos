"""
DAG para orquestar el procesamiento mensual de la tabla tension_dep para todo el a√±o 2019
Este DAG procesa los datos mes por mes, insert√°ndolos en tension_dep_processed,
verificando primero que no existan datos duplicados.
"""

from datetime import datetime, timedelta
import os
import requests
import time
import calendar
import subprocess
import json
import psycopg2
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.bash import BashOperator
from airflow.operators.dummy import DummyOperator
from airflow.models import Variable
from airflow.hooks.base import BaseHook
from airflow.utils.task_group import TaskGroup
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.models import Connection
from airflow import settings

# Configuraci√≥n de par√°metros
MINI_PROXY_URL = "http://mini_nifi_proxy_centrosur:5001"  # URL del proxy
HTTP_TIMEOUT = 60  # Timeout para peticiones HTTP en segundos

# Grupo Productor y Consumidor
PRODUCER_GROUP_ID = "f35dfed5-6e7e-33cd-8455-234c0136d8c7"  # Grupo Productor
CONSUMER_GROUP_ID = "19683749-d095-382d-8a05-74b3b36f934c"  # Grupo Consumidor

# IDs de procesadores - Grupo Productor
QUERY_DB_TABLE_PROCESSOR_ID = (
    "e9f8d7b7-0195-1000-b079-ca7c436c3eba"  # QueryDatabaseTable
)
LOG_ATTRIBUTE_PRODUCER_ID1 = "e9fb71ae-0195-1000-5c0e-5efbccb6ebcc"
CONVERT_RECORD_ID = "e9fbf7ed-0195-1000-149d-c8dea531eda2"
LOG_ATTRIBUTE_PRODUCER_ID2 = "e9fee94a-0195-1000-6104-08a6a2bacc22"
SPLIT_JSON_ID = "e9fc0bd1-0195-1000-218b-3e18c352e877"
LOG_ATTRIBUTE_PRODUCER_ID3 = "e9ff61c3-0195-1000-ac37-fd51994cecc4"
MERGE_CONTENT_ID = "e9fc8676-0195-1000-b1de-1b04dc87f02c"
PUBLISH_KAFKA_ID = "e9fc66be-0195-1000-f243-a7ff628dd677"

# IDs de procesadores - Grupo Consumidor
CONSUME_KAFKA_PROCESSOR_ID = "ea033b4c-0195-1000-6a80-16a36b4734e1"
LOG_ATTRIBUTE_CONSUMER_ID1 = "ea035a50-0195-1000-d145-ffeadb1d3d38"
EVALUATE_JSON_PATH_ID = "ea03791a-0195-1000-6453-8e70e2baf71d"
REPLACE_TEXT_ID = "ea038fff-0195-1000-bb41-90056ffaad3d"
LOG_ATTRIBUTE_CONSUMER_ID2 = "ea03b65b-0195-1000-c17e-cd0f56c0551c"
PUT_DB_PROCESSOR_ID = "ea03d72b-0195-1000-59e1-05be97cd9ef5"
LOG_ATTRIBUTE_CONSUMER_ID3 = "ea03f66b-0195-1000-634b-076c5c4bd1a2"


# Configuraci√≥n del DAG
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "start_date": datetime(2025, 3, 1),
    "email_on_failure": False,
    "email_on_retry": False,
    "retries": 2,
    "retry_delay": timedelta(minutes=2),
}

dag = DAG(
    "tension_integrador_anual",
    default_args=default_args,
    description="Procesamiento mensual de datos de tensi√≥n para el a√±o 2019",  
    schedule_interval=None,
    catchup=False,
    tags=["centrosur", "tension", "anual", "nifi", "kafka"],  
)


# FUNCIONES DE UTILIDAD
def create_postgres_connections():
    """Create required Postgres connections if they don't exist"""
    connections = [
        {
            "conn_id": "postgres_centrosur",
            "conn_type": "postgres",
            "host": "postgres_centrosur",
            "login": "postgres",
            "password": "1150040812",
            "schema": "centrosur",
            "port": 5432,
        },
        {
            "conn_id": "postgres_base_prueba",
            "conn_type": "postgres",
            "host": "postgres_centrosur",  # Same host
            "login": "postgres",
            "password": "1150040812",
            "schema": "base_prueba",  # Different database
            "port": 5432,
        },
    ]
    session = settings.Session()
    for conn_info in connections:
        conn = Connection(**conn_info)
        existing_conn = (
            session.query(Connection).filter(Connection.conn_id == conn.conn_id).first()
        )
        if existing_conn:
            session.delete(existing_conn)
            session.commit()
        session.add(conn)
    session.commit()
    session.close()
    print("‚úÖ Postgres connections created/updated successfully")


def verificar_proxy_disponible():
    """Verifica que el proxy NiFi est√© disponible"""
    max_intentos = 5
    for intento in range(1, max_intentos + 1):
        try:
            print(
                f"Verificando disponibilidad del proxy NiFi (intento {intento}/{max_intentos})..."
            )
            response = requests.get(f"{MINI_PROXY_URL}/health", timeout=HTTP_TIMEOUT)

            # Registrar respuesta completa para diagn√≥stico
            print(
                f"Respuesta del proxy: Status={response.status_code}, Contenido={response.text[:200]}..."
            )

            if response.status_code == 200:
                data = response.json()
                # Verificar si el proxy reporta un estado saludable
                if data.get("status") == "healthy" or data.get("auth_working"):
                    print(f"Proxy NiFi est√° disponible y reporta estado saludable")
                    print(f"Detalles adicionales: {json.dumps(data)}")
                    return True
                else:
                    print(
                        f"Proxy disponible pero reporta estado: {data.get('status')}, mensaje: {data.get('message')}"
                    )
                    # Verificar informaci√≥n de autenticaci√≥n y conexi√≥n con NiFi
                    if "nifi_connected" in data:
                        print(f"Conexi√≥n con NiFi: {data.get('nifi_connected')}")
                    if "auth_working" in data:
                        print(f"Autenticaci√≥n funcionando: {data.get('auth_working')}")
                    if data.get("auth_working"):
                        return True
            else:
                print(
                    f"Proxy no disponible (intento {intento}/{max_intentos}): {response.status_code}"
                )
                print(f"Respuesta: {response.text[:200]}...")
        except requests.exceptions.ConnectionError as e:
            print(
                f"Error de conexi√≥n al proxy (intento {intento}/{max_intentos}): {str(e)}"
            )
            print(
                "Esto podr√≠a indicar que el servicio proxy no est√° en ejecuci√≥n o no es accesible en la red."
            )
        except requests.exceptions.Timeout as e:
            print(
                f"Timeout al conectar con el proxy (intento {intento}/{max_intentos}): {str(e)}"
            )
            print(
                "Esto podr√≠a indicar que el servicio proxy est√° sobrecargado o no responde."
            )
        except Exception as e:
            print(
                f"Error al verificar proxy (intento {intento}/{max_intentos}): {str(e)}"
            )

        if intento < max_intentos:
            print(f"Esperando 5 segundos antes de reintentar...")
            time.sleep(5)

    raise Exception("El proxy NiFi no est√° disponible despu√©s de m√∫ltiples intentos")

def decidir_ruta_mes(ti, mes, nombre_mes):
    """Funci√≥n helper para determinar la ruta correcta"""
    # Verificar el resultado expl√≠citamente
    resultado = ti.xcom_pull(task_ids=f"procesar_{nombre_mes}.verificar_si_{nombre_mes}_ya_procesado")
    print(f"Resultado de verificaci√≥n para mes {mes}: {resultado}")
    
    if resultado:
        print(f"‚úÖ DECISI√ìN: Mes {mes} ya procesado, SALTANDO...")
        return f"procesar_{nombre_mes}.skip_y_verificar.skip_{nombre_mes}"
    else:
        print(f"üîÑ DECISI√ìN: Mes {mes} necesita procesarse")
        return f"procesar_{nombre_mes}.camino_procesamiento.procesar_mes_{mes}"
def obtener_estado_procesador(id_procesador):
    """Obtiene el estado actual de un procesador a trav√©s del mini-proxy"""
    try:
        response = requests.get(
            f"{MINI_PROXY_URL}/api/processors/{id_procesador}", timeout=HTTP_TIMEOUT
        )

        if response.status_code == 200:
            datos_procesador = response.json()
            return datos_procesador
        else:
            return {
                "error": f"Error al obtener estado del procesador: {response.status_code}",
                "raw_response": response.text,
            }
    except Exception as e:
        return {"error": f"Error al consultar procesador: {str(e)}"}


def detener_procesador(id_procesador):
    """Detiene un procesador espec√≠fico en NiFi"""
    try:
        # Primero obtenemos el estado actual y la revisi√≥n
        processor_data = obtener_estado_procesador(id_procesador)

        # Verificar si el procesador existe
        if "error" in processor_data:
            print(
                f"WARNING: El procesador {id_procesador} no existe o hay un error: {processor_data['error']}"
            )
            return f"Warning: Procesador {id_procesador} no encontrado"

        # Extraemos la informaci√≥n necesaria
        current_state = processor_data.get("component", {}).get("state")
        revision = processor_data.get("revision", {})

        print(
            f"Estado actual del procesador {id_procesador} para detener: {current_state}"
        )

        # Si ya est√° detenido o deshabilitado, no hacer nada
        if current_state in ["STOPPED", "DISABLED"]:
            return f"Procesador {id_procesador} ya est√° detenido o deshabilitado"

        # Si no se pudo obtener el estado, devolver mensaje
        if not current_state:
            return f"No se pudo obtener el estado del procesador {id_procesador} para detener"

        # Preparamos los datos para actualizar el estado
        update_data = {
            "revision": revision,
            "component": {"id": id_procesador, "state": "STOPPED"},
        }

        # Enviamos la solicitud para cambiar el estado
        response = requests.put(
            f"{MINI_PROXY_URL}/api/processors/{id_procesador}",
            json=update_data,
            timeout=HTTP_TIMEOUT,
        )

        if response.status_code == 200:
            return f"Procesador {id_procesador} detenido correctamente"
        else:
            return f"Error al detener procesador: {response.status_code}"
    except Exception as e:
        return f"Excepci√≥n al detener procesador: {str(e)}"


def iniciar_procesador_con_reintento(processor_id, processor_name, max_retries=5):
    """Inicia un procesador con reintentos y verificaci√≥n mejorada"""
    for intento in range(1, max_retries + 1):
        try:
            print(f"   Intento {intento}/{max_retries} para iniciar {processor_name}")

            # Obtener estado actual y revisi√≥n
            datos_procesador = obtener_estado_procesador(processor_id)
            estado_actual = datos_procesador.get("component", {}).get("state")
            revision = datos_procesador.get("revision", {})

            print(f"   Estado actual: {estado_actual}")

            if estado_actual == "RUNNING":
                print(f"   ‚úÖ {processor_name} ya est√° en estado RUNNING")
                return f"‚úÖ {processor_name} ya est√° en estado RUNNING"

            # Preparar datos para actualizar estado
            update_data = {
                "revision": revision,
                "component": {"id": processor_id, "state": "RUNNING"},
            }

            # Enviar solicitud para cambiar estado
            response = requests.put(
                f"{MINI_PROXY_URL}/api/processors/{processor_id}",
                json=update_data,
                timeout=HTTP_TIMEOUT,
            )

            if response.status_code == 200:
                # Verificar que el cambio fue efectivo
                time.sleep(3)  # Esperar m√°s tiempo para confirmar el cambio
                new_status = obtener_estado_procesador(processor_id)
                new_state = new_status.get("component", {}).get("state")

                print(f"   Nuevo estado despu√©s de inicio: {new_state}")

                if new_state == "RUNNING":
                    print(f"   ‚úÖ {processor_name} iniciado correctamente")
                    return f"‚úÖ {processor_name} iniciado correctamente"
            else:
                print(
                    f"   ‚ùå Error c√≥digo {response.status_code}: {response.text[:100]}"
                )

            # Si llegamos aqu√≠, o el inicio fall√≥ o no se verific√≥ correctamente
            if intento < max_retries:
                print(f"   ‚è≥ Esperando 5 segundos antes de reintentar...")
                time.sleep(5)

        except Exception as e:
            print(f"   ‚ùå Error: {str(e)}")
            if intento < max_retries:
                time.sleep(5)

    # Si despu√©s de todos los intentos no logramos iniciar, devolver mensaje de error
    print(f"   ‚ö†Ô∏è No se pudo iniciar {processor_name} despu√©s de {max_retries} intentos")
    return f"‚ö†Ô∏è No se pudo iniciar {processor_name} despu√©s de {max_retries} intentos"


def stop_all_processors_individually():
    """Detiene todos los procesadores individuales en lugar de grupos completos"""
    try:
        producer_processors = [
            QUERY_DB_TABLE_PROCESSOR_ID,
            LOG_ATTRIBUTE_PRODUCER_ID1,
            CONVERT_RECORD_ID,
            LOG_ATTRIBUTE_PRODUCER_ID2,
            SPLIT_JSON_ID,
            LOG_ATTRIBUTE_PRODUCER_ID3,
            MERGE_CONTENT_ID,
            PUBLISH_KAFKA_ID,
        ]

        # Lista de procesadores del consumidor
        consumer_processors = [
            CONSUME_KAFKA_PROCESSOR_ID,
            LOG_ATTRIBUTE_CONSUMER_ID1,
            EVALUATE_JSON_PATH_ID,
            REPLACE_TEXT_ID,
            LOG_ATTRIBUTE_CONSUMER_ID2,
            PUT_DB_PROCESSOR_ID,
            LOG_ATTRIBUTE_CONSUMER_ID3,
        ]

        print("üìå Deteniendo procesadores del productor individualmente...")
        for processor_id in producer_processors:
            detener_procesador(processor_id)

        print("üìå Deteniendo procesadores del consumidor individualmente...")
        for processor_id in consumer_processors:
            detener_procesador(processor_id)

        # Esperar para que los procesadores se detengan
        time.sleep(15)

        return f"Todos los procesadores detenidos individualmente: {len(producer_processors) + len(consumer_processors)} procesadores"
    except Exception as e:
        print(f"‚ùå Error al detener procesadores: {str(e)}")
        return f"Error al detener procesadores: {str(e)}"


def iniciar_todos_procesadores_en_secuencia():
    """Inicia todos los procesadores en secuencia correcta con validaci√≥n"""
    results = []

    # Lista completa de todos los procesadores en orden correcto
    todos_procesadores = [
        # Grupo productor
        {
            "id": QUERY_DB_TABLE_PROCESSOR_ID,
            "name": "QueryDatabaseTable",
            "group": "producer",
        },
        {
            "id": LOG_ATTRIBUTE_PRODUCER_ID1,
            "name": "LogAttribute1",
            "group": "producer",
        },
        {"id": CONVERT_RECORD_ID, "name": "ConvertRecord", "group": "producer"},
        {
            "id": LOG_ATTRIBUTE_PRODUCER_ID2,
            "name": "LogAttribute2",
            "group": "producer",
        },
        {"id": SPLIT_JSON_ID, "name": "SplitJson", "group": "producer"},
        {
            "id": LOG_ATTRIBUTE_PRODUCER_ID3,
            "name": "LogAttribute3",
            "group": "producer",
        },
        {"id": MERGE_CONTENT_ID, "name": "MergeContent", "group": "producer"},
        {"id": PUBLISH_KAFKA_ID, "name": "PublishKafka", "group": "producer"},
        # Grupo consumidor
        {"id": CONSUME_KAFKA_PROCESSOR_ID, "name": "ConsumeKafka", "group": "consumer"},
        {
            "id": LOG_ATTRIBUTE_CONSUMER_ID1,
            "name": "LogAttribute4",
            "group": "consumer",
        },
        {"id": EVALUATE_JSON_PATH_ID, "name": "EvaluateJsonPath", "group": "consumer"},
        {"id": REPLACE_TEXT_ID, "name": "ReplaceText", "group": "consumer"},
        {
            "id": LOG_ATTRIBUTE_CONSUMER_ID2,
            "name": "LogAttribute5",
            "group": "consumer",
        },
        {"id": PUT_DB_PROCESSOR_ID, "name": "PutDatabaseRecord", "group": "consumer"},
        {
            "id": LOG_ATTRIBUTE_CONSUMER_ID3,
            "name": "LogAttribute6",
            "group": "consumer",
        },
    ]
    # Iniciar primero el grupo productor COMPLETO
    print("‚ñ∂Ô∏è Iniciando grupo PRODUCTOR completo...")
    for proc in [p for p in todos_procesadores if p["group"] == "producer"]:
        print(f"‚ñ∂Ô∏è Iniciando {proc['name']}...")
        result = iniciar_procesador_con_reintento(proc["id"], proc["name"])
        results.append(result)

        # Verificar estado despu√©s del inicio
        verify_state = obtener_estado_procesador(proc["id"])
        current_state = verify_state.get("component", {}).get("state", "UNKNOWN")
        print(f"   Estado actual de {proc['name']}: {current_state}")

        time.sleep(3)  # Pausa entre inicios

    # Esperar antes de iniciar consumidores
    print("‚è≥ Esperando 10 segundos para que los productores inicien completamente...")
    time.sleep(10)

    # Luego iniciar el grupo consumidor COMPLETO
    print("‚ñ∂Ô∏è Iniciando grupo CONSUMIDOR completo...")
    for proc in [p for p in todos_procesadores if p["group"] == "consumer"]:
        print(f"‚ñ∂Ô∏è Iniciando {proc['name']}...")
        result = iniciar_procesador_con_reintento(proc["id"], proc["name"])
        results.append(result)

        # Verificar estado despu√©s del inicio
        verify_state = obtener_estado_procesador(proc["id"])
        current_state = verify_state.get("component", {}).get("state", "UNKNOWN")
        print(f"   Estado actual de {proc['name']}: {current_state}")

        time.sleep(3)  # Pausa entre inicios

    return f"Iniciados {len(results)} procesadores en secuencia"


def iniciar_todos_procesadores_por_grupo():
    """Inicia todos los procesadores de ambos grupos uno por uno (reemplaza versi√≥n fallida)"""
    try:
        results = {}

        # Lista de procesadores del productor con IDs ACTUALIZADOS
        producer_processors = [
            {"id": QUERY_DB_TABLE_PROCESSOR_ID, "name": "QueryDatabaseTable"},
            {"id": LOG_ATTRIBUTE_PRODUCER_ID1, "name": "LogAttribute1"},
            {"id": CONVERT_RECORD_ID, "name": "ConvertRecord"},
            {"id": LOG_ATTRIBUTE_PRODUCER_ID2, "name": "LogAttribute2"},
            {"id": SPLIT_JSON_ID, "name": "SplitJson"},
            {"id": LOG_ATTRIBUTE_PRODUCER_ID3, "name": "LogAttribute3"},
            {"id": MERGE_CONTENT_ID, "name": "MergeContent"},
            {"id": PUBLISH_KAFKA_ID, "name": "PublishKafka"},
        ]
        # Lista de procesadores del consumidor con IDs ACTUALIZADOS
        consumer_processors = [
            {"id": CONSUME_KAFKA_PROCESSOR_ID, "name": "ConsumeKafka"},
            {"id": LOG_ATTRIBUTE_CONSUMER_ID1, "name": "LogAttribute4"},
            {"id": EVALUATE_JSON_PATH_ID, "name": "EvaluateJsonPath"},
            {"id": REPLACE_TEXT_ID, "name": "ReplaceText"},
            {"id": LOG_ATTRIBUTE_CONSUMER_ID2, "name": "LogAttribute5"},
            {"id": PUT_DB_PROCESSOR_ID, "name": "PutDatabaseRecord"},
            {"id": LOG_ATTRIBUTE_CONSUMER_ID3, "name": "LogAttribute6"},
        ]
        # Iniciar cada procesador individualmente - PRODUCTOR
        print("‚ñ∂Ô∏è Iniciando procesadores del productor individualmente...")
        for processor in producer_processors:
            result = iniciar_procesador_con_reintento(
                processor["id"], processor["name"], max_retries=3
            )
            results[f"producer_{processor['name']}"] = result
            time.sleep(3)  # Breve pausa entre cada inicio

        # Esperar antes de iniciar consumidores
        print(
            "‚è≥ Esperando 15 segundos para que los productores inicien completamente..."
        )
        time.sleep(15)
        # Iniciar cada procesador individualmente - CONSUMIDOR
        print("‚ñ∂Ô∏è Iniciando procesadores del consumidor individualmente...")
        for processor in consumer_processors:
            result = iniciar_procesador_con_reintento(
                processor["id"], processor["name"], max_retries=3
            )
            results[f"consumer_{processor['name']}"] = result
            time.sleep(3)  # Breve pausa entre cada inicio
        return True
    except Exception as e:
        print(f"‚ùå Error iniciando procesadores: {str(e)}")
        return False


def configurar_topic_procesador(processor_id, property_name, topic_name):
    """Configura un procesador Kafka para usar un topic espec√≠fico"""
    try:
        # Obtener el estado actual del procesador
        processor_data = obtener_estado_procesador(processor_id)

        if "error" in processor_data:
            print(
                f"‚õî ERROR: No se pudo obtener el estado del procesador: {processor_data}"
            )
            return False

        revision = processor_data.get("revision", {})
        component = processor_data.get("component", {})
        properties = component.get("properties", {})

        # Guardar el topic actual para diagn√≥stico
        topic_actual = properties.get(property_name, "desconocido")
        print(f"üìã Topic actual en {processor_id}: {topic_actual}")

        # Actualizar la propiedad del topic
        properties[property_name] = topic_name

        # Enviar actualizaci√≥n al procesador
        update_data = {
            "revision": revision,
            "component": {"id": processor_id, "properties": properties},
        }

        # Primero asegurarse que el procesador est√© detenido
        detener_procesador(processor_id)
        time.sleep(5)

        update_response = requests.put(
            f"{MINI_PROXY_URL}/api/processors/{processor_id}",
            json=update_data,
            timeout=HTTP_TIMEOUT,
        )

        if update_response.status_code == 200:
            print(
                f"‚úÖ Topic actualizado correctamente a {topic_name} en {processor_id}"
            )
            return True
        else:
            print(f"‚ùå Error al actualizar topic: {update_response.status_code}")
            print(f"üìä Respuesta: {update_response.text[:200]}")
            return False

    except Exception as e:
        print(f"‚ùå Error al configurar topic: {str(e)}")
        return False


def limpiar_estado_procesador(processor_id):
    """Limpia el estado del procesador QueryDatabaseTable para forzar procesamiento desde cero"""
    host = "588a471cac3f"  # ID del contenedor confirmado

    try:
        print(f"üßπ Limpiando estado del procesador {processor_id}...")

        # 1. Obtener token
        cmd_token = f"curl -k -s -X POST -d 'username=admin&password=centrosur123' https://{host}:8443/nifi-api/access/token"
        token_process = subprocess.run(
            cmd_token, shell=True, capture_output=True, text=True
        )
        token = token_process.stdout.strip()

        if not token:
            print("‚ùå Error obteniendo token de autenticaci√≥n")
            return False

        # 2. Limpiar el estado del procesador
        cmd_clear = f"curl -k -s -X POST -H 'Authorization: Bearer {token}' -H 'Content-Type: application/json' https://{host}:8443/nifi-api/processors/{processor_id}/state/clear-requests"

        clear_process = subprocess.run(
            cmd_clear, shell=True, capture_output=True, text=True
        )
        if clear_process.returncode == 0:
            print("‚úÖ Estado del procesador limpiado correctamente")
            return True
        else:
            print(f"‚ùå Error limpiando estado: {clear_process.stderr}")
            return False

    except Exception as e:
        print(f"‚ùå Error general limpiando estado: {str(e)}")
        return False


def clear_processor_state_and_empty_all_queues():
    """Completely clears processor state and empties all connection queues"""
    try:
        print(
            "üßπ Performing complete cleanup of processor state and connection queues..."
        )

        # 1. Stop all processors first
        print("üìå Deteniendo procesadores del productor individualmente...")
        stop_all_processors_individually()
        time.sleep(5)  # Allow time for processors to stop

        # 2. Get token for direct NiFi API access
        host = "588a471cac3f"  # Container ID that works consistently
        cmd_token = f"curl -k -s -X POST -d 'username=admin&password=centrosur123' https://{host}:8443/nifi-api/access/token"
        token_process = subprocess.run(
            cmd_token, shell=True, capture_output=True, text=True
        )
        token = token_process.stdout.strip()

        if not token:
            print("‚ö†Ô∏è Couldn't get token, trying alternative method...")
            # Even without token, try to continue with other methods

        # 3. Clear state of the main processor - multiple attempts with different methods
        if token:
            # Method 1: Standard clear request
            cmd_clear = f"curl -k -s -X POST -H 'Authorization: Bearer {token}' https://{host}:8443/nifi-api/processors/{QUERY_DB_TABLE_PROCESSOR_ID}/state/clear-requests"
            subprocess.run(cmd_clear, shell=True)

            # Method 2: Get all connections and empty them
            cmd_get_connections = f"curl -k -s -X GET -H 'Authorization: Bearer {token}' -H 'Accept: application/json' https://{host}:8443/nifi-api/process-groups/{PRODUCER_GROUP_ID}/connections"
            conn_result = subprocess.run(
                cmd_get_connections, shell=True, capture_output=True, text=True
            )

            try:
                connections = json.loads(conn_result.stdout)
                if "connections" in connections:
                    for conn in connections["connections"]:
                        conn_id = conn.get("id")
                        cmd_empty = f"curl -k -s -X POST -H 'Authorization: Bearer {token}' -H 'Content-Type: application/json' -d '{{\"disconnectedNodeAcknowledged\":false}}' https://{host}:8443/nifi-api/flowfile-queues/{conn_id}/drop-requests"
                        subprocess.run(cmd_empty, shell=True)
            except:
                print("‚ö†Ô∏è Could not empty connection queues with token")

        # 4. Also use the mini-proxy for thorough cleanup
        try:
            response = requests.post(
                f"{MINI_PROXY_URL}/api/processors/{QUERY_DB_TABLE_PROCESSOR_ID}/state/clear",
                timeout=10,
            )

            # Also try to empty connection queues
            for group_id in [PRODUCER_GROUP_ID, CONSUMER_GROUP_ID]:
                response = requests.get(
                    f"{MINI_PROXY_URL}/api/process-groups/{group_id}/connections",
                    timeout=10,
                )

                if response.status_code == 200:
                    connections = response.json()
                    if "connections" in connections:
                        for conn in connections["connections"]:
                            conn_id = conn.get("id")
                            requests.post(
                                f"{MINI_PROXY_URL}/api/flowfile-queues/{conn_id}/drop-requests",
                                json={"disconnectedNodeAcknowledged": False},
                                timeout=10,
                            )
        except:
            # Continue even if this method fails
            pass

        time.sleep(10)  # Allow time for cleanup operations to complete
        print("‚úÖ Cleanup operations completed")
        return True

    except Exception as e:
        print(f"‚ö†Ô∏è Error in cleanup: {str(e)}")
        # Continue anyway to ensure the flow doesn't stop
        return True


def truncate_existing_month_data(mes_inicio, mes_fin, ano=2019):
    """Removes existing data for the month to allow clean reprocessing"""
    try:
        fecha_inicio = f"{ano}-{mes_inicio:02d}-01"
        fecha_fin = f"{ano}-{mes_fin:02d}-01"

        print(
            f"üóëÔ∏è Limpiando datos existentes en destino para {fecha_inicio} a {fecha_fin}"
        )
        pg_hook_destino = PostgresHook(postgres_conn_id="postgres_base_prueba")

        # Delete existing records for this month
        delete_query = f"""
        DELETE FROM tension_dep_processed 
        WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
        """

        rows_deleted = pg_hook_destino.run(delete_query)
        print(f"‚úÖ Eliminando {rows_deleted} datos del mes {mes_inicio}")
        return True

    except Exception as e:
        print(f"‚ùå Error al eliminar datos del mes: {str(e)}")
        return False


def actualizar_consulta_sin_docker(processor_id, tabla_temporal):
    """Actualiza la consulta SQL sin depender de Docker"""
    try:
        print(f"üîÑ Actualizando consulta para usar tabla temporal {tabla_temporal}...")

        # Crear la consulta que usa EXCLUSIVAMENTE la tabla temporal
        nueva_consulta = f"""/* TABLA_TEMPORAL_EXCLUSIVA_{int(time.time())} */
SELECT 
    fecha, 
    hora, 
    id_subestacion, 
    dia_semana, 
    tension_servicio
FROM tension_dep
ORDER BY fecha, hora, id_subestacion
"""

        # Obtener estado del procesador
        processor_data = obtener_estado_procesador(processor_id)

        if "error" in processor_data:
            print(f"‚ö†Ô∏è Error obteniendo estado: {processor_data['error']}")
            return False

        revision = processor_data.get("revision", {})
        component = processor_data.get("component", {})
        properties = dict(component.get("properties", {}))

        # Mostrar consulta actual para diagn√≥stico
        consulta_actual = properties.get("Custom Query", "NO DISPONIBLE")
        print(f"üìã Consulta actual: {consulta_actual[:100]}...")

        # Actualizar consulta
        properties["Custom Query"] = nueva_consulta
        properties["db-fetch-sql-query"] = nueva_consulta  # Nombre alternativo

        # Remover propiedades problem√°ticas
        for key in [
            "start_date",
            "end_date",
            "Maximum-value Column",
            "Maximum-value Columns",
        ]:
            if key in properties:
                del properties[key]

        # Crear datos para actualizaci√≥n
        update_data = {
            "revision": revision,
            "component": {"id": processor_id, "properties": properties},
        }

        # Enviar actualizaci√≥n
        response = requests.put(
            f"{MINI_PROXY_URL}/api/processors/{processor_id}",
            json=update_data,
            timeout=HTTP_TIMEOUT,
        )

        if response.status_code == 200:
            print(f"‚úÖ Consulta actualizada correctamente para usar {tabla_temporal}")

            # Verificaci√≥n de actualizaci√≥n
            time.sleep(3)
            verify_data = obtener_estado_procesador(processor_id)
            updated_query = (
                verify_data.get("component", {})
                .get("properties", {})
                .get("Custom Query", "")
            )

            if tabla_temporal in updated_query:
                print("‚úÖ Verificaci√≥n confirma actualizaci√≥n correcta")
                return True
            else:
                print("‚ö†Ô∏è Verificaci√≥n no encontr√≥ la tabla temporal en la consulta")
                print(f"Consulta actual: {updated_query[:100]}...")
        else:
            print(f"‚ùå Error actualizando consulta: {response.status_code}")
            print(f"Respuesta: {response.text[:200]}")

        return False
    except Exception as e:
        print(f"‚ùå Error actualizando consulta: {str(e)}")
        return False


def decidir_procesar_mes(ti, mes, grupo):
    """Decide si procesar un mes basado en verificaci√≥n previa"""
    verificacion_key = f"procesar_{grupo}.verificar_si_{grupo}_ya_procesado"
    if not ti.xcom_pull(task_ids=verificacion_key):
        return f"procesar_{grupo}.procesar_mes_{mes}"
    else:
        return f"procesar_{grupo}.skip_{grupo}"

def get_token_with_retry(max_retries=3):
    """Obtiene token con reintentos en caso de fallo"""
    host = "588a471cac3f"  # Container ID
    
    for intento in range(1, max_retries + 1):
        try:
            print(f"üîë Intento {intento}/{max_retries} de obtener token...")
            cmd_token = f"curl -k -s -X POST -d 'username=admin&password=centrosur123' https://{host}:8443/nifi-api/access/token"
            token_process = subprocess.run(cmd_token, shell=True, capture_output=True, text=True, timeout=30)
            
            token = token_process.stdout.strip()
            if token and len(token) > 20:  # Token v√°lido suele ser largo
                print("‚úÖ Token obtenido correctamente")
                return token
            
            # Intento alternativo con el mini-proxy si est√° disponible
            print("‚ö†Ô∏è M√©todo directo fall√≥, intentando con mini-proxy...")
            response = requests.post(
                f"{MINI_PROXY_URL}/api/get-token",
                json={"username": "admin", "password": "centrosur123"},
                timeout=HTTP_TIMEOUT
            )
            
            if response.status_code == 200:
                token_data = response.json()
                if "token" in token_data:
                    print("‚úÖ Token obtenido v√≠a mini-proxy")
                    return token_data["token"]
                    
            time.sleep(2 * intento)  # Espera creciente entre intentos
            
        except Exception as e:
            print(f"‚ö†Ô∏è Error en intento {intento}: {str(e)}")
            time.sleep(2 * intento)
    
    print("‚ùå No se pudo obtener token despu√©s de varios intentos")
    return None

def configurar_put_database_record():
    """Configura el procesador PutDatabaseRecord para usar INSERT en lugar de UPSERT"""
    try:
        print("üîß Configurando procesador PutDatabaseRecord...")
        processor_data = obtener_estado_procesador(PUT_DB_PROCESSOR_ID)
        
        if "error" in processor_data:
            print(f"‚ö†Ô∏è Error obteniendo estado: {processor_data['error']}")
            return False
            
        revision = processor_data.get("revision", {})
        component = processor_data.get("component", {})
        properties = dict(component.get("properties", {}))
        
        # Mostrar configuraci√≥n actual
        statement_type_actual = properties.get("put-db-record-statement-type", "DESCONOCIDO")
        print(f"üîç Tipo de declaraci√≥n actual: {statement_type_actual}")
        
        # Cambiar de UPSERT a INSERT
        properties["put-db-record-statement-type"] = "INSERT"
        
        # Crear datos para actualizaci√≥n
        update_data = {
            "revision": revision,
            "component": {"id": PUT_DB_PROCESSOR_ID, "properties": properties}
        }
        
        # Detener primero el procesador
        detener_procesador(PUT_DB_PROCESSOR_ID)
        time.sleep(5)
        
        # Enviar actualizaci√≥n
        response = requests.put(
            f"{MINI_PROXY_URL}/api/processors/{PUT_DB_PROCESSOR_ID}",
            json=update_data,
            timeout=HTTP_TIMEOUT
        )
        
        if response.status_code == 200:
            print("‚úÖ PutDatabaseRecord configurado para usar INSERT")
            return True
        else:
            print(f"‚ùå Error configurando PutDatabaseRecord: {response.status_code}")
            return False
            
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        return False

def procesar_mes_sustituyendo_tabla(mes, **kwargs):
    """
    Crea una tabla temporal y aplica el M√âTODO NUCLEAR SEGURO para garantizar
    que solo se procesan datos del mes espec√≠fico, pero con restauraci√≥n garantizada.
    """
    try:
        # Inicializaci√≥n de variables
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        ano = 2019
        mes_siguiente = mes + 1 if mes < 12 else 1
        ano_siguiente = ano if mes < 12 else ano + 1
        fecha_inicio = f"{ano}-{mes:02d}-01"
        fecha_fin = f"{ano_siguiente}-{mes_siguiente:02d}-01"
        print(f"üö® AISLAMIENTO SEGURO para mes {mes} ({fecha_inicio} a {fecha_fin})")
        
        # VERIFICACI√ìN INICIAL: Asegurar que tension_dep est√° completa
        count_inicial = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
        print(f"üìä VERIFICACI√ìN INICIAL: tension_dep tiene {count_inicial} registros totales")
        
        # Detener todos los procesadores para asegurar un entorno limpio
        print("‚è∏Ô∏è Deteniendo todos los procesadores...")
        stop_all_processors_individually()
        time.sleep(30)  # Tiempo extra para asegurar detenci√≥n completa
        
        # 1. CREAR BACKUP DE LA TABLA ORIGINAL SIEMPRE (redundancia de seguridad)
        backup_tabla = f"tension_dep_prev_{int(time.time())}"
        print(f"üîí Creando backup de seguridad de tabla original: {backup_tabla}")
        pg_hook.run(f"CREATE TABLE {backup_tabla} AS SELECT * FROM tension_dep")
        
        # Registrar el nombre del backup para recuperaci√≥n posterior
        kwargs['ti'].xcom_push(key=f'mes_{mes}_backup_table', value=backup_tabla)
        
        # 2. CREAR NOMBRE √öNICO PARA LA TABLA TEMPORAL DE TRABAJO
        tabla_trabajo = f"tension_dep_work_{int(time.time())}"
        print(f"üìã Creando tabla de trabajo {tabla_trabajo}...")
        
        # 3. Eliminar tabla si existe (por seguridad)
        pg_hook.run(f"DROP TABLE IF EXISTS {tabla_trabajo}")
        
        # 4. Verificar registros existentes para este mes
        query_verificar = f"""
            SELECT COUNT(*) FROM tension_dep 
            WHERE EXTRACT(MONTH FROM fecha) = {mes}
            AND EXTRACT(YEAR FROM fecha) = {ano}
        """
        count = pg_hook.get_first(query_verificar)[0]
        
        if count == 0:
            print(f"‚ö†Ô∏è No hay datos para el mes {mes} en tension_dep. Abortando procesamiento.")
            return False
        
        print(f"‚úÖ Encontrados {count} registros en tension_dep para el mes {mes}")
        
        # 5. CREAR LA TABLA DE TRABAJO con filtros de fecha estrictos
        create_query = f"""
            CREATE TABLE {tabla_trabajo} AS
            SELECT * FROM tension_dep 
            WHERE EXTRACT(MONTH FROM fecha) = {mes}
            AND EXTRACT(YEAR FROM fecha) = {ano}
            AND fecha >= '{fecha_inicio}'
            AND fecha < '{fecha_fin}'
        """
        pg_hook.run(create_query)
            
        # 6. Verificar creaci√≥n correcta
        count_trabajo = pg_hook.get_first(f"SELECT COUNT(*) FROM {tabla_trabajo}")[0]
        print(f"‚úÖ Tabla de trabajo {tabla_trabajo} creada con {count_trabajo} registros exclusivos del mes {mes}")
        
        # 7. Registrar la tabla trabajo para limpieza posterior
        kwargs['ti'].xcom_push(key=f'tabla_trabajo_mes_{mes}', value=tabla_trabajo)
        
        # 8. *** M√âTODO NUCLEAR SEGURO CON TABLA TEMPORAL PARA ORIGINAL ***
        print("‚ò¢Ô∏è APLICANDO M√âTODO NUCLEAR SEGURO...")
        
        # a. Renombrar la tabla original temporalmente (mantener nombre consistente para facilitar recuperaci√≥n)
        temp_original = f"tension_dep_original_temp_{mes}_{int(time.time())}"
        pg_hook.run(f"ALTER TABLE tension_dep RENAME TO {temp_original}")
        print(f"üîÑ Tabla original renombrada temporalmente a {temp_original}")
        
        # b. Crear nueva tabla tension_dep con solo datos del mes 
        pg_hook.run(f"CREATE TABLE tension_dep AS SELECT * FROM {tabla_trabajo}")
        print(f"‚ö° SOLUCI√ìN NUCLEAR: tension_dep ahora contiene SOLO datos del mes {mes}")
        
        # c. Guardar el nombre de la tabla original temporal usando el mes como clave
        kwargs['ti'].xcom_push(key=f'tension_dep_original_temp_{mes}', value=temp_original)
        
        # Tambi√©n guardarlo en una clave gen√©rica para facilitar recuperaci√≥n
        kwargs['ti'].xcom_push(key='ultima_tabla_original_temp', value=temp_original)
            
        # 9. Configurar consulta simple
        nueva_consulta = f"""/* CONSULTA_MES_{mes}_{int(time.time())} */
SELECT 
    fecha, 
    hora, 
    id_subestacion, 
    dia_semana, 
    tension_servicio
FROM tension_dep
ORDER BY fecha, hora, id_subestacion
"""
        
        # Obtener estado del procesador
        processor_data = obtener_estado_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
        revision = processor_data.get("revision", {})
        component = processor_data.get("component", {})
        properties = dict(component.get("properties", {}))
        
        # Modificar consulta y eliminar Table Name
        properties["db-fetch-sql-query"] = nueva_consulta
        properties["Custom Query"] = nueva_consulta
        properties["Table Name"] = ""
        
        update_data = {
            "revision": revision,
            "component": {
                "id": QUERY_DB_TABLE_PROCESSOR_ID,
                "properties": properties
            }
        }
        
        # Enviar actualizaci√≥n
        response = requests.put(
            f"{MINI_PROXY_URL}/api/processors/{QUERY_DB_TABLE_PROCESSOR_ID}",
            json=update_data,
            timeout=HTTP_TIMEOUT
        )
        
        if response.status_code == 200:
            print(f"‚úÖ Consulta SQL configurada correctamente")
            
            # Verificaci√≥n adicional
            time.sleep(5)
            verificacion = obtener_estado_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
            consulta_actual = verificacion.get("component", {}).get("properties", {}).get("db-fetch-sql-query", "")
            tabla_nombre = verificacion.get("component", {}).get("properties", {}).get("Table Name", "")
            
            print(f"üîç VERIFICACI√ìN: Table Name = '{tabla_nombre}'")
            print(f"üîç VERIFICACI√ìN: Consulta simple: {'tension_dep' in consulta_actual}")
        else:
            print(f"‚ö†Ô∏è Error actualizando consulta: {response.status_code}")
            return False
        
        # 10. Limpiar datos existentes en destino
        print("üóëÔ∏è Limpiando datos existentes en destino...")
        pg_hook_destino = PostgresHook(postgres_conn_id="postgres_base_prueba")
        pg_hook_destino.run(f"""
            DELETE FROM tension_dep_processed 
            WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
        """)
        
        # 11. Configurar topic Kafka √∫nico
        topic_name = f"tension-mes{mes}-seguro-{int(time.time())}"
        print(f"üîÑ Configurando topic Kafka √∫nico: {topic_name}")
        configurar_topic_procesador(PUBLISH_KAFKA_ID, "Topic Name", topic_name)
        configurar_topic_procesador(CONSUME_KAFKA_PROCESSOR_ID, "topic", topic_name)
        # 11b. Configurar PutDatabaseRecord para INSERT en lugar de UPSERT
        configurar_put_database_record()
        # 12. Limpiar estado y colas
        print("üßπ Limpiando estado del procesador y colas...")
        limpiar_estado_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
        clear_processor_state_and_empty_all_queues()
        
        # 13. Iniciar procesadores
        print("‚ñ∂Ô∏è Iniciando grupos de procesadores completos...")
        iniciar_todos_procesadores_por_grupo()
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        import traceback
        print(f"Detalles del error: {traceback.format_exc()}")
        
        # Intentar restaurar la tabla original antes de salir
        try:
            pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
            
            # Buscar el nombre de la tabla temporal reci√©n creada
            temp_original = kwargs.get('ti').xcom_pull(key=f'tension_dep_original_temp_{mes}')
            
            if temp_original:
                # Verificar si la tabla existe
                if pg_hook.get_first(
                    f"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{temp_original}')"
                )[0]:
                    # Eliminar la tabla tension_dep parcial
                    pg_hook.run("DROP TABLE IF EXISTS tension_dep")
                    
                    # Restaurar desde la temporal
                    pg_hook.run(f"ALTER TABLE {temp_original} RENAME TO tension_dep")
                    print(f"üö® RESTAURACI√ìN DE EMERGENCIA: Tabla original restaurada desde {temp_original}")
            
            # Si no se encontr√≥ la temporal espec√≠fica, intentar con el backup
            else:
                backup_tabla = kwargs.get('ti').xcom_pull(key=f'mes_{mes}_backup_table')
                
                if backup_tabla and pg_hook.get_first(
                    f"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{backup_tabla}')"
                )[0]:
                    pg_hook.run("DROP TABLE IF EXISTS tension_dep")
                    pg_hook.run(f"ALTER TABLE {backup_tabla} RENAME TO tension_dep")
                    print(f"üö® RESTAURACI√ìN DE EMERGENCIA: Tabla original restaurada desde backup {backup_tabla}")
            
        except Exception as cleanup_error:
            print(f"‚ö†Ô∏è Error adicional durante restauraci√≥n de emergencia: {str(cleanup_error)}")
            
        return False

def verificar_tablas_temporales():
    """Muestra todas las tablas temporales actualmente existentes"""
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        query = """
        SELECT table_name FROM information_schema.tables 
        WHERE table_name LIKE 'tension_dep_%'
        """
        tablas = pg_hook.get_records(query)
        print(f"‚ÑπÔ∏è Tablas temporales existentes ({len(tablas)}):")
        for tabla in tablas:
            print(f"  - {tabla[0]}")
        return tablas
    except Exception as e:
        print(f"‚ùå Error verificando tablas: {str(e)}")
        return []

def verificar_y_restaurar_tabla_original_al_inicio():
    """
    Verifica el estado de la tabla tension_dep y la restaura desde tension_dep_original
    si es necesario, antes de comenzar cualquier procesamiento.
    """
    try:
        print("üîç Verificando integridad de la tabla original tension_dep...")
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")

        # 1. Verificar si existe el respaldo original
        respaldo_existe = pg_hook.get_first(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep_original')"
        )[0]

        if not respaldo_existe:
            print(
                "‚ö†Ô∏è No se encontr√≥ respaldo tension_dep_original. Se crear√° si existe la tabla original."
            )

            # Verificar si existe la tabla original
            original_existe = pg_hook.get_first(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
            )[0]

            if original_existe:
                print("üìã Creando respaldo inicial tension_dep_original...")
                pg_hook.run(
                    "CREATE TABLE tension_dep_original AS SELECT * FROM tension_dep"
                )
                print("‚úÖ Respaldo inicial creado exitosamente")
                return "Respaldo inicial creado"
            else:
                print(
                    "‚ùå ERROR CR√çTICO: No existe ni la tabla original ni el respaldo!"
                )
                return "Error: No existen tablas necesarias"

        # 2. Verificar si existe la tabla original
        original_existe = pg_hook.get_first(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
        )[0]

        if not original_existe:
            print("‚ö†Ô∏è Tabla tension_dep no existe. Restaurando desde respaldo...")
            pg_hook.run(
                "CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original"
            )
            print("‚úÖ Tabla tension_dep restaurada desde respaldo")
            return "Tabla restaurada desde respaldo"

        # 3. Verificar integridad comparando conteos
        count_original = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
        count_backup = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep_original")[
            0
        ]

        print(f"üìä Conteo en tension_dep: {count_original}")
        print(f"üìä Conteo en tension_dep_original: {count_backup}")

        # Si hay una gran diferencia, restaurar desde respaldo
        if count_original < count_backup * 0.9:  # Si tiene menos del 90% de registros
            print(
                f"‚ö†Ô∏è Tabla tension_dep parece inconsistente ({count_original} vs {count_backup})"
            )
            print("üîÑ Restaurando tabla completa desde respaldo...")

            # Backup de la tabla actual por si acaso
            backup_nombre = f"tension_dep_backup_{int(time.time())}"
            pg_hook.run(f"CREATE TABLE {backup_nombre} AS SELECT * FROM tension_dep")
            print(f"üìã Se cre√≥ respaldo adicional: {backup_nombre}")

            # Restaurar desde respaldo original
            pg_hook.run("DROP TABLE tension_dep")
            pg_hook.run(
                "CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original"
            )
            print("‚úÖ Tabla tension_dep restaurada completamente desde respaldo")
            return "Tabla restaurada por inconsistencia"

        # 4. Limpieza de tablas temporales antiguas
        query_tablas_temp = """
        SELECT table_name FROM information_schema.tables 
        WHERE table_name LIKE 'tension_dep_prev_%' OR table_name LIKE 'tension_dep_temp_%'
        """
        tablas_temp = pg_hook.get_records(query_tablas_temp)

        if tablas_temp:
            print(f"üßπ Limpiando {len(tablas_temp)} tablas temporales antiguas...")
            for tabla in tablas_temp:
                pg_hook.run(f"DROP TABLE IF EXISTS {tabla[0]}")
            print("‚úÖ Limpieza de tablas temporales completada")

        return "Verificaci√≥n completada: Tabla original √≠ntegra"

    except Exception as e:
        print(f"‚ùå Error verificando tabla original: {str(e)}")
        return f"Error: {str(e)}"

def procesar_y_restaurar_mes(mes, **kwargs):
    """Procesa el mes utilizando la funci√≥n de sustituci√≥n de tabla y gestiona los casos sin datos"""
    try:
        # VERIFICACI√ìN CR√çTICA - Confirmar que tension_dep tiene todos los datos
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        # 1. Verificar que tension_dep contiene datos de diferentes meses
        otros_meses = pg_hook.get_records("""
            SELECT EXTRACT(MONTH FROM fecha) as mes, COUNT(*) 
            FROM tension_dep 
            GROUP BY EXTRACT(MONTH FROM fecha)
            ORDER BY mes
        """)
        
        print(f"üìä VERIFICACI√ìN PREVIA para mes {mes} - Distribuci√≥n en tension_dep:")
        for m in otros_meses:
            mes_num = int(m[0])
            print(f"  - Mes {mes_num}: {m[1]} registros")
        
        # Si solo hay un mes y no es 1 (enero), probable error de restauraci√≥n
        if len(otros_meses) <= 1 and mes > 1:
            print(f"‚ö†Ô∏è ALERTA CR√çTICA: tension_dep solo contiene datos de un mes, pero estamos procesando mes {mes}")
            print(f"üîÑ Intentando restauraci√≥n de emergencia antes de procesar...")
            
            # Restaurar desde tension_dep_original
            if pg_hook.get_first(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep_original')"
            )[0]:
                # Hacer backup del estado actual por si acaso
                backup_actual = f"tension_dep_backup_emergencia_{int(time.time())}"
                pg_hook.run(f"CREATE TABLE {backup_actual} AS SELECT * FROM tension_dep")
                
                # Restaurar desde original
                pg_hook.run("DROP TABLE IF EXISTS tension_dep")
                pg_hook.run("CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original")
                print(f"üÜò RESTAURACI√ìN DE EMERGENCIA completada antes de procesar mes {mes}")
                
                # Verificar nuevamente
                count_restaurado = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
                print(f"üìä Tabla tension_dep restaurada con {count_restaurado} registros totales")
        
        # VERIFICACI√ìN ADICIONAL: Si ya hay datos, no procesar
        pg_hook_destino = PostgresHook(postgres_conn_id="postgres_base_prueba")
        query = f"""
        SELECT COUNT(*) FROM tension_dep_processed 
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = 2019
        """
        count = pg_hook_destino.get_first(query)[0]
        if count > 0:
            print(f"üîí VERIFICACI√ìN REDUNDANTE: El mes {mes} ya tiene {count} registros. NO SE PROCESAR√Å.")
            return True
        
        # VERIFICACI√ìN M√ÅS COMPLETA: Buscar en todas las fuentes posibles
        # Primero verificar en tension_dep_original
        tiene_datos = verificar_existencia_datos_fuente(mes)
        
        if not tiene_datos:
            # Registramos esta situaci√≥n para informaci√≥n
            kwargs['ti'].xcom_push(key=f'mes_{mes}_datos_no_detectados', value=True)
            print(f"‚ö†Ô∏è Advertencia: No se detectaron datos en origen principal para el mes {mes}")
            print(f"üîç Intentando buscar en fuentes alternativas...")
            kwargs['ti'].xcom_push(key=f'mes_{mes}_sin_datos_reales', value=True)
            print(f"‚ö†Ô∏è NO HAY DATOS para el mes {mes}. Se ha verificado en todas las fuentes disponibles.")
            print(f"‚ö†Ô∏è Este no es un error del DAG, simplemente no hay datos para procesar.")
            return True
        
        # Si hay datos, ejecutar el procesamiento
        print(f"üöÄ Iniciando procesamiento del mes {mes}...")
        resultado_procesamiento = procesar_mes_sustituyendo_tabla(mes, **kwargs)
        
        return resultado_procesamiento
    except Exception as e:
        print(f"‚ùå Error procesando mes {mes}: {str(e)}")
        
        # Restauraci√≥n de emergencia si hay error
        try:
            pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
            pg_hook.run("DROP TABLE IF EXISTS tension_dep")
            pg_hook.run("CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original")
            print(f"üÜò RESTAURACI√ìN DE EMERGENCIA tras error en procesar_y_restaurar_mes: {mes}")
        except Exception as e2:
            print(f"‚ùå Error secundario en restauraci√≥n: {str(e2)}")
            
        return False

def verificar_completitud_mes(mes, umbral=99.0, **kwargs):
    """Verifica que el mes procesado haya alcanzado el umbral de completitud"""
    try:
        pg_hook_origen = PostgresHook(postgres_conn_id="postgres_centrosur")
        pg_hook_destino = PostgresHook(postgres_conn_id="postgres_base_prueba")

        # Contar registros en origen para este mes
        query_origen = f"""
        SELECT COUNT(*) FROM public.tension_dep_original
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = 2019
        """
        total_origen = pg_hook_origen.get_first(query_origen)[0]

        # Contar registros en destino para este mes
        query_destino = f"""
        SELECT COUNT(*) FROM tension_dep_processed
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = 2019
        """
        total_destino = pg_hook_destino.get_first(query_destino)[0]

        # Calcular completitud
        if total_origen > 0:
            completitud = (total_destino / total_origen) * 100
            print(
                f"üìä Completitud del mes {mes}: {completitud:.2f}% ({total_destino}/{total_origen})"
            )

            # Verificar si alcanza el umbral
            if completitud >= umbral:
                print(
                    f"‚úÖ Mes {mes} alcanz√≥ umbral de completitud ({completitud:.2f}% ‚â• {umbral}%)"
                )
                return True
            else:
                print(
                    f"‚ö†Ô∏è Mes {mes} no alcanz√≥ umbral de completitud ({completitud:.2f}% < {umbral}%)"
                )
                return False
        else:
            print(f"‚ö†Ô∏è No hay datos en origen para el mes {mes}")
            return False

    except Exception as e:
        print(f"‚ùå Error verificando completitud del mes {mes}: {str(e)}")
        return False

def esperar_verificar_y_finalizar_mes(mes, tiempo_espera_minutos=12, **kwargs):
    """Espera el tiempo especificado y da m√°s tiempo a los procesadores"""
    try:
        # ‚ú® TRATAMIENTO ESPECIAL PARA DICIEMBRE (MES 12) ‚ú®
        if mes == 12:
            tiempo_espera_minutos = 20  # Dar m√°s tiempo a Diciembre por su volumen
            print(f"‚è±Ô∏è AJUSTE ESPECIAL: Aumentando tiempo de espera para Diciembre a {tiempo_espera_minutos} minutos")

        pg_hook = PostgresHook(postgres_conn_id="postgres_base_prueba")
        ano = 2019
        
        # Verificar si se marc√≥ que no hay datos para este mes
        ti = kwargs.get('ti')
        if ti and ti.xcom_pull(key=f'mes_{mes}_sin_datos_reales'):
            print(f"‚ö†Ô∏è El mes {mes} fue marcado como sin datos. Saltando espera/verificaci√≥n.")
            return True
        
        print(f"‚è≥ Iniciando espera de {tiempo_espera_minutos} minutos para el mes {mes}...")
        
        # Calcular tiempo total de espera en segundos
        tiempo_total_segundos = tiempo_espera_minutos * 60
        intervalo_verificacion = 60  # Verificar cada 60 segundos

        # Query para verificar registros
        query = f"""
        SELECT COUNT(*) FROM tension_dep_processed 
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = {ano}
        """

        # Variables para seguimiento
        ultimo_conteo = 0
        conteo_estable = 0
        tiempo_transcurrido = 0

        # Bucle de espera con verificaciones peri√≥dicas
        while tiempo_transcurrido < tiempo_total_segundos:
            # Verificar conteo actual
            conteo_actual = pg_hook.get_first(query)[0]

            print(f"üìä Verificaci√≥n a los {tiempo_transcurrido} segundos: {conteo_actual} registros procesados para mes {mes}")

            # Verificaci√≥n de estabilidad
            if conteo_actual > 0:
                if conteo_actual == ultimo_conteo:
                    conteo_estable += 1
                    print(f"  ‚è≥ Conteo estable ({conteo_actual}) durante {conteo_estable} verificaciones")

                    if conteo_estable >= 5:
                        print(f"‚úÖ Procesamiento completado para mes {mes}: {conteo_actual} registros")
                        # Espera adicional para asegurar procesamiento completo
                        print(f"‚è≥ Esperando 60 segundos adicionales para asegurar finalizaci√≥n completa...")
                        time.sleep(60)
                        break
                else:
                    # Reiniciar contador de estabilidad si el conteo cambia
                    conteo_estable = 0

            ultimo_conteo = conteo_actual

            # Extender tiempo si hay progreso cerca del l√≠mite
            if (tiempo_transcurrido >= tiempo_total_segundos * 0.8 and 
                conteo_actual > 0 and 
                conteo_estable < 5):
                print(f"‚ö†Ô∏è Extendiendo tiempo de espera para asegurar finalizaci√≥n...")
                tiempo_total_segundos += 180  # A√±adir 3 minutos m√°s

            # Esperar para la siguiente verificaci√≥n
            time.sleep(intervalo_verificacion)
            tiempo_transcurrido += intervalo_verificacion
        
        # A√±adir tiempo extra para procesamiento
        print(f"‚è≥ Asegurando tiempo adicional para procesamiento completo...")
        time.sleep(120)  # 2 minutos adicionales para asegurar el procesamiento
        
        # Al finalizar, detener procesadores de forma m√°s efectiva
        print(f"‚èπÔ∏è Deteniendo procesadores ordenadamente despu√©s de procesar mes {mes}...")
        stop_all_processors_individually()
        time.sleep(15)  # Esperar para asegurar detenci√≥n
        
        # RESTAURACI√ìN GARANTIZADA DESDE tension_dep_original
        print(f"üîÑ RESTAURANDO TABLA ORIGINAL desde tension_dep_original despu√©s de procesar mes {mes}...")
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")

        # Eliminar la tabla tension_dep actual (que solo tiene datos del mes procesado)
        pg_hook.run("DROP TABLE IF EXISTS tension_dep")

        # Restaurar directamente desde tension_dep_original (manera m√°s segura)
        pg_hook.run("CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original")
        print("‚úÖ Tabla tension_dep restaurada completamente desde tension_dep_original")

        # Verificar restauraci√≥n
        count_total = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
        print(f"üìä Tabla original restaurada con {count_total} registros TOTALES")
        
        # Verificar que contiene datos de otros meses
        otros_meses = pg_hook.get_records("""
            SELECT EXTRACT(MONTH FROM fecha) as mes, COUNT(*) 
            FROM tension_dep 
            GROUP BY EXTRACT(MONTH FROM fecha)
            ORDER BY mes
        """)
        print(f"üìä Distribuci√≥n por mes despu√©s de restaurar:")
        for m in otros_meses:
            print(f"  - Mes {int(m[0])}: {m[1]} registros")
            
        # TRATAMIENTO ESPECIAL PARA DICIEMBRE
        if mes == 12:
            print("üõë DETENCI√ìN ESPECIAL PARA DICIEMBRE: Asegurando apagado completo")
            # Detener todos los procesadores con m√©todo agresivo
            stop_all_processors_individually()
            time.sleep(10)  # Esperar 10 segundos
            
            # Segunda pasada para verificar que realmente se detuvieron
            stop_all_processors_individually()
            time.sleep(10)  # Esperar otros 10 segundos
            
            # Verificar expl√≠citamente
            print("üîç Verificando detenci√≥n de procesadores cr√≠ticos...")
            
            # Verificar QUERY_DB_TABLE_PROCESSOR_ID
            estado = obtener_estado_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
            estado_actual = estado.get("component", {}).get("state", "UNKNOWN")
            print(f"  QueryDatabaseTable: {estado_actual}")
            
            # Si a√∫n no se ha detenido, intentar una vez m√°s
            if estado_actual != "STOPPED":
                print("  ‚ö†Ô∏è Forzando detenci√≥n...")
                detener_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
                
            # Verificar tambi√©n el procesador de Kafka
            estado_kafka = obtener_estado_procesador(PUBLISH_KAFKA_ID)
            estado_kafka_actual = estado_kafka.get("component", {}).get("state", "UNKNOWN")
            print(f"  PublishKafka: {estado_kafka_actual}")
            if estado_kafka_actual != "STOPPED":
                print("  ‚ö†Ô∏è Forzando detenci√≥n de Kafka...")
                detener_procesador(PUBLISH_KAFKA_ID)
                
            return True
        else:
            # Para otros meses, detener de forma normal
            # Primero detener QueryDatabaseTable para evitar nuevos datos
            detener_procesador(QUERY_DB_TABLE_PROCESSOR_ID)
            time.sleep(5)
            
            # Luego detener los dem√°s procesadores
            stop_all_processors_individually()
            
        return True  # Mantener esta funci√≥n con valor de retorno consistente
    except Exception as e:
        print(f"‚ùå Error durante espera: {str(e)}")
        
        # RESTAURACI√ìN DE EMERGENCIA en caso de error
        try:
            pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
            pg_hook.run("DROP TABLE IF EXISTS tension_dep")
            pg_hook.run("CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original")
            print("üÜò RESTAURACI√ìN DE EMERGENCIA completada debido a error")
        except Exception as e2:
            print(f"‚ùå Error adicional en restauraci√≥n de emergencia: {str(e2)}")
            
        return False


def restaurar_estado_original_completo():
    """
    Asegura que la base de datos vuelva a su estado original, eliminando tablas temporales
    y restaurando tension_dep como la √∫nica tabla principal.
    """
    try:
        print("üîÑ Verificando y restaurando estado original de la base de datos...")
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        # 1. Verificar existencia de tablas
        tension_dep_existe = pg_hook.get_first(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
        )[0]
        
        original_existe = pg_hook.get_first(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep_original')"
        )[0]
        
        # 2. RESTAURACI√ìN FINAL: Eliminar tension_dep_original y mantener solo tension_dep
        if tension_dep_existe and original_existe:
            # Contar registros para comparaci√≥n
            count_tension_dep = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
            count_original = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep_original")[0]
            
            print(f"üìä Registros en tension_dep: {count_tension_dep}")
            print(f"üìä Registros en tension_dep_original: {count_original}")
            
            # PASO FINAL: Eliminar tension_dep_original como solicitado
            pg_hook.run("DROP TABLE IF EXISTS tension_dep_original")
            print("‚úÖ TABLA tension_dep_original ELIMINADA - Restauraci√≥n completada")
        
        # 3. Buscar y eliminar todas las tablas temporales
        query_tablas_temp = """
        SELECT table_name FROM information_schema.tables 
        WHERE (table_name LIKE 'tension_dep_%') 
        AND table_name != 'tension_dep' AND table_name != 'tension_dep_processed'
        """
        
        tablas_temp = pg_hook.get_records(query_tablas_temp)
        
        if tablas_temp:
            print(f"üßπ Eliminando {len(tablas_temp)} tablas temporales...")
            for tabla in tablas_temp:
                nombre_tabla = tabla[0]
                pg_hook.run(f"DROP TABLE IF EXISTS {nombre_tabla}")
                print(f"  üóëÔ∏è Eliminada tabla: {nombre_tabla}")
        
        # 4. Verificar estado final
        count_final = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
        print(f"üìä ESTADO FINAL: Tabla tension_dep contiene {count_final} registros")
        
        return f"Base de datos restaurada a estado original. Eliminadas {len(tablas_temp)} tablas temporales."
        
    except Exception as e:
        print(f"‚ùå Error al restaurar estado original: {str(e)}")
        return f"Error: {str(e)}"

def esperar_verificar_y_restaurar_mes(mes, tiempo_espera_minutos=12, **kwargs):
    """
    Espera el tiempo especificado mientras monitorea el procesamiento del mes,
    verifica si se guardaron correctamente los datos, y restaura la tabla original.
    """
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_base_prueba")
        ano = 2019

        print(
            f"‚è≥ Iniciando espera de {tiempo_espera_minutos} minutos para el mes {mes}..."
        )

        # Calcular tiempo total de espera en segundos
        tiempo_total_segundos = tiempo_espera_minutos * 60
        intervalo_verificacion = 60  # Verificar cada 60 segundos

        # Query para verificar registros
        query = f"""
        SELECT COUNT(*) FROM tension_dep_processed 
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = {ano}
        """

        # Variables para seguimiento
        ultimo_conteo = 0
        conteo_estable = 0
        tiempo_transcurrido = 0

        # Bucle de espera con verificaciones peri√≥dicas
        while tiempo_transcurrido < tiempo_total_segundos:
            # Verificar conteo actual
            conteo_actual = pg_hook.get_first(query)[0]

            print(
                f"üìä Verificaci√≥n a los {tiempo_transcurrido} segundos: {conteo_actual} registros procesados para mes {mes}"
            )

            # Verificaci√≥n de estabilidad mejorada
            if conteo_actual > 0:
                if conteo_actual == ultimo_conteo:
                    conteo_estable += 1
                    print(
                        f"  ‚è≥ Conteo estable ({conteo_actual}) durante {conteo_estable} verificaciones"
                    )

                    # Requerir m√°s verificaciones consecutivas (5 en lugar de 3)
                    if conteo_estable >= 5:
                        print(
                            f"‚úÖ Procesamiento completado para mes {mes}: {conteo_actual} registros"
                        )
                        # A√±adir una pausa extra para asegurar que todos los datos est√©n procesados
                        print(
                            f"‚è≥ Esperando 60 segundos adicionales para asegurar finalizaci√≥n completa..."
                        )
                        time.sleep(60)
                        break
                else:
                    # Reiniciar contador de estabilidad si el conteo cambia
                    conteo_estable = 0

            ultimo_conteo = conteo_actual

            # Si estamos cerca del tiempo l√≠mite pero hay progreso, extender el tiempo
            if (
                tiempo_transcurrido >= tiempo_total_segundos * 0.8
                and conteo_actual > 0
                and conteo_estable < 5
            ):
                print(f"‚ö†Ô∏è Extendiendo tiempo de espera para asegurar finalizaci√≥n...")
                tiempo_total_segundos += 180  # A√±adir 3 minutos m√°s

            # Esperar para la siguiente verificaci√≥n
            time.sleep(intervalo_verificacion)
            tiempo_transcurrido += intervalo_verificacion

        # Agregar espera adicional al final para asegurar procesamiento completo
        print(
            f"‚è≥ Esperando 60 segundos adicionales para asegurar que no queden datos en cola..."
        )
        time.sleep(60)

        # Detener procesadores despu√©s de esperar
        print(f"‚èπÔ∏è Deteniendo procesadores despu√©s de esperar para mes {mes}...")
        stop_all_processors_individually()
        time.sleep(30)  # M√°s tiempo para asegurar detenci√≥n completa

        # Verificaci√≥n final
        conteo_final = pg_hook.get_first(query)[0]
        print(f"üìä Verificaci√≥n final: {conteo_final} registros para mes {mes}")

        # Restaurar tabla original
        print(f"üîÑ Restaurando tabla original despu√©s de procesar mes {mes}...")
        restaurar_tabla_original_v2(**kwargs)

        # Comprobar si se guardaron suficientes datos
        if conteo_final > 0:
            print(
                f"‚úÖ Mes {mes} procesado y guardado exitosamente con {conteo_final} registros"
            )
            return True
        else:
            print(f"‚ùå No se guardaron datos para el mes {mes} o hubo un problema")
            return False

    except Exception as e:
        print(f"‚ùå Error durante espera y verificaci√≥n del mes {mes}: {str(e)}")

        # Intentar restaurar la tabla en caso de error
        try:
            print(f"üîÑ Intentando restaurar tabla original despu√©s de error...")
            stop_all_processors_individually()
            time.sleep(30)  # M√°s tiempo para asegurar detenci√≥n completa
            restaurar_tabla_original_v2(**kwargs)
        except Exception as e2:
            print(f"‚ùå Error adicional al restaurar tabla: {str(e2)}")

        return False

def verificar_disponibilidad_datos_por_mes():
    """Genera un informe de disponibilidad de datos por mes en la tabla origen"""
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        print("üìä VERIFICACI√ìN DE DISPONIBILIDAD DE DATOS POR MES EN TABLA ORIGEN")
        print("=" * 60)
        
        disponibilidad = {}
        
        for mes in range(1, 13):
            # Calcular fechas para cada mes
            mes_siguiente = mes + 1 if mes < 12 else 1
            ano_siguiente = 2019 if mes < 12 else 2020
            fecha_inicio = f"2019-{mes:02d}-01"
            fecha_fin = f"{ano_siguiente}-{mes_siguiente:02d}-01"
            
            # Consulta para verificar datos
            query = f"""
            SELECT COUNT(*) 
            FROM tension_dep_original
            WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
            """
            
            count = pg_hook.get_first(query)[0]
            disponibilidad[mes] = count
            
            if count > 0:
                print(f"‚úÖ MES {mes:2d} ({calendar.month_name[mes]:>9}): {count:,} registros disponibles")
            else:
                print(f"‚ùå MES {mes:2d} ({calendar.month_name[mes]:>9}): SIN DATOS")
        
        print("=" * 60)
        print(f"Total de meses con datos: {sum(1 for count in disponibilidad.values() if count > 0)}/12")
        
        return disponibilidad
    except Exception as e:
        print(f"‚ùå Error verificando disponibilidad: {str(e)}")
        return {}

def verificar_existencia_datos_fuente(mes, ano=2019, **kwargs):
    """Verifica si existen datos REALES para un mes espec√≠fico en CUALQUIER tabla disponible"""
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")

        # Calcular el rango de fechas para el mes
        mes_siguiente = mes + 1 if mes < 12 else 1
        ano_siguiente = ano if mes < 12 else ano + 1
        fecha_inicio = f"{ano}-{mes:02d}-01"
        fecha_fin = f"{ano_siguiente}-{mes_siguiente:02d}-01"

        # Para octubre o cualquier mes, buscar en todas las fuentes posibles
        print(f"üîç B√öSQUEDA EXHAUSTIVA: Buscando datos REALES del mes {mes} en todas las tablas disponibles")
        
        # 1. Verificar en tension_dep_original (fuente est√°ndar)
        query_original = f"""
        SELECT COUNT(*) FROM tension_dep_original  
        WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
        """
        count_original = pg_hook.get_first(query_original)[0]
        
        if count_original > 0:
            print(f"‚úÖ Encontrados {count_original} registros reales para mes {mes} en tension_dep_original")
            return True
            
        # 2. Verificar en tension_dep (tabla principal)
        query_main = f"""
        SELECT COUNT(*) FROM tension_dep 
        WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
        """
        count_main = pg_hook.get_first(query_main)[0]
        
        if count_main > 0:
            print(f"‚úÖ Encontrados {count_main} registros reales para mes {mes} en tension_dep principal")
            return True
            
        # 3. Buscar en TODAS las tablas que podr√≠an tener datos reales
        print(f"üîé Buscando en todas las tablas relacionadas...")
        
        # Obtener todas las tablas potenciales
        query_tablas = """
        SELECT table_name FROM information_schema.tables 
        WHERE table_name LIKE 'potencia_%' 
        AND table_schema = 'public'
        """
        
        tablas = pg_hook.get_records(query_tablas)
        
        for tabla in tablas:
            tabla_nombre = tabla[0]
            # Evitar tablas ya verificadas
            if tabla_nombre not in ['tension_dep', 'tension_dep_original', 'tension_dep_processed']:
                try:
                    # Verificar si tiene datos para el mes
                    check_query = f"""
                    SELECT COUNT(*) FROM {tabla_nombre}
                    WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
                    """
                    count = pg_hook.get_first(check_query)[0]
                    
                    if count > 0:
                        print(f"‚úÖ ENCONTRADOS {count} registros REALES del mes {mes} en tabla {tabla_nombre}")
                        return True
                except:
                    # Algunas tablas pueden no tener la estructura esperada
                    pass
        
        # 4. Buscar en todas las bases de datos disponibles
        try:
            print(f"üîé Ampliando b√∫squeda a otras bases de datos...")
            # Listar bases de datos
            databases_query = """
            SELECT datname FROM pg_database 
            WHERE datistemplate = false
            """
            all_databases = pg_hook.get_records(databases_query)
            
            for db in all_databases:
                db_name = db[0]
                if db_name not in ['centrosur', 'base_prueba', 'postgres', 'template0', 'template1']:
                    try:
                        # Conectar a otra base de datos
                        conn_params = pg_hook.get_connection('postgres_centrosur')
                        conn = psycopg2.connect(
                            host=conn_params.host,
                            port=conn_params.port,
                            dbname=db_name,
                            user=conn_params.login,
                            password=conn_params.password
                        )
                        cur = conn.cursor()
                        
                        # Verificar tablas relacionadas
                        cur.execute("SELECT table_name FROM information_schema.tables WHERE table_name LIKE 'potencia_%'")
                        db_tables = cur.fetchall()
                        
                        for db_table in db_tables:
                            table_name = db_table[0]
                            try:
                                # Verificar datos
                                cur.execute(f"SELECT COUNT(*) FROM {table_name} WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'")
                                count = cur.fetchone()[0]
                                
                                if count > 0:
                                    print(f"‚úÖ ENCONTRADOS {count} registros REALES del mes {mes} en base {db_name}, tabla {table_name}")
                                    # Cerrar conexi√≥n
                                    cur.close()
                                    conn.close()
                                    return True
                            except:
                                pass
                        
                        # Cerrar conexi√≥n
                        cur.close()
                        conn.close()
                    except:
                        print(f"‚ö†Ô∏è No se pudo conectar a base de datos {db_name}")
        except:
            print("‚ö†Ô∏è Error al buscar en bases de datos adicionales")
            
        # Si llegamos aqu√≠, realmente no hay datos
        print(f"‚ùå CONFIRMADO: No existen datos reales para el mes {mes} en NINGUNA tabla o base de datos")
        print(f"‚ùå No se generar√°n datos artificiales siguiendo el requerimiento del usuario")
        
        # Marcar como sin datos reales
        if 'ti' in kwargs and kwargs['ti']:
            kwargs['ti'].xcom_push(key=f'mes_{mes}_datos_no_detectados', value=True)
            kwargs['ti'].xcom_push(key=f'mes_{mes}_sin_datos_reales', value=True)
            
        return False
            
    except Exception as e:
        print(f"‚ùå Error verificando datos fuente: {str(e)}")
        return False

def restaurar_tabla_original_v2(**kwargs):
    """Restaura la tabla original de manera segura y completa"""
    try:
        print("üîÑ Restaurando tabla original tension_dep...")
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        # 1. Intentar recuperar el nombre de la tabla temporal actual
        ti = kwargs.get('ti')
        
        # Buscar primero el nombre de la tabla temporal creada durante el procesamiento
        temp_original = None
        for mes in range(1, 13):
            temp_name = ti.xcom_pull(key=f'tension_dep_original_temp_{mes}')
            if temp_name:
                temp_original = temp_name
                print(f"üîç Encontrada tabla temporal del mes {mes}: {temp_original}")
                break
                
        if temp_original:
            # Verificar que ambas tablas existan
            temp_existe = pg_hook.get_first(
                f"SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = '{temp_original}')"
            )[0]
            
            tension_dep_existe = pg_hook.get_first(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
            )[0]
            
            if temp_existe:
                # Eliminar la tabla tension_dep actual (solo tiene datos de un mes)
                if tension_dep_existe:
                    pg_hook.run("DROP TABLE IF EXISTS tension_dep")
                    print("üóëÔ∏è Tabla parcial tension_dep eliminada")
                
                # Restaurar tabla original con TODOS los datos
                pg_hook.run(f"ALTER TABLE {temp_original} RENAME TO tension_dep")
                print(f"‚úÖ Tabla original restaurada desde {temp_original}")
                
                # Verificar conteo
                count = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
                print(f"üìä Tabla tension_dep restaurada con {count} registros totales")
                return f"Tabla restaurada exitosamente desde {temp_original}"
        
        # Si el m√©todo anterior falla, intentar con la tabla de respaldo
        query_tablas_temp = """
        SELECT table_name FROM information_schema.tables 
        WHERE table_name LIKE 'tension_dep_prev_%' 
        ORDER BY table_name DESC
        LIMIT 1
        """
        
        # Obtener la tabla temporal m√°s reciente para restaurar
        tablas_temp = pg_hook.get_records(query_tablas_temp)
        
        if tablas_temp and len(tablas_temp) > 0:
            backup_table = tablas_temp[0][0]
            print(f"üîç Encontrada tabla de respaldo: {backup_table}")
            
            # Eliminar tabla actual si existe
            tension_dep_existe = pg_hook.get_first(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
            )[0]
            
            if tension_dep_existe:
                pg_hook.run("DROP TABLE IF EXISTS tension_dep")
                print("üóëÔ∏è Tabla tension_dep actual eliminada para restauraci√≥n completa")
                
            # Restaurar desde la tabla de respaldo
            pg_hook.run(f"ALTER TABLE {backup_table} RENAME TO tension_dep")
            print(f"‚úÖ Tabla original restaurada desde respaldo {backup_table}")
            
            # Verificar restauraci√≥n
            count = pg_hook.get_first("SELECT COUNT(*) FROM tension_dep")[0]
            print(f"üìä Tabla tension_dep restaurada con {count} registros totales")
            
            return f"Tabla restaurada desde respaldo {backup_table}"
        
        # Si todo lo anterior falla, intentar con tension_dep_original
        original_exists = pg_hook.get_first(
            "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep_original')"
        )[0]
        
        if original_exists:
            # Eliminar tabla actual si existe
            tension_dep_existe = pg_hook.get_first(
                "SELECT EXISTS (SELECT FROM information_schema.tables WHERE table_name = 'tension_dep')"
            )[0]
            
            if tension_dep_existe:
                pg_hook.run("DROP TABLE IF EXISTS tension_dep")
            
            # Crear desde respaldo original
            pg_hook.run("CREATE TABLE tension_dep AS SELECT * FROM tension_dep_original")
            print("‚úÖ Tabla tension_dep recreada desde respaldo original tension_dep_original")
            return "Tabla recreada desde respaldo original"
        
        print("‚ö†Ô∏è ERROR CR√çTICO: No se pudo restaurar la tabla original por ning√∫n m√©todo")
        return "ERROR: No se pudo restaurar la tabla original"
        
    except Exception as e:
        print(f"‚ùå Error al restaurar tabla: {str(e)}")
        import traceback
        print(f"Detalles del error: {traceback.format_exc()}")
        return f"Error: {str(e)}"

def verificar_y_corregir_mes_completo_al_finalizar(mes, **kwargs):
    """Verifica que SOLO existan datos del mes correcto y corrige si es necesario"""
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_base_prueba")
        
        # Obtener distribuci√≥n actual por mes
        query_dist = """
        SELECT EXTRACT(MONTH FROM fecha) as mes, COUNT(*) 
        FROM tension_dep_processed 
        WHERE EXTRACT(YEAR FROM fecha) = 2019
        GROUP BY EXTRACT(MONTH FROM fecha)
        ORDER BY mes
        """
        
        distribucion = pg_hook.get_records(query_dist)
        print(f"üîç VERIFICACI√ìN FINAL MES {mes}: Distribuci√≥n de registros en tabla procesada")
        
        # Variables para seguimiento
        total_registros = 0
        registros_mes_correcto = 0
        
        for m in distribucion:
            mes_num = int(m[0])
            cantidad = m[1]
            total_registros += cantidad
            
            if mes_num == mes:
                registros_mes_correcto = cantidad
                print(f"  ‚úÖ Mes {mes_num}: {cantidad} registros (MES CORRECTO)")
            else:
                print(f"  ‚ùå Mes {mes_num}: {cantidad} registros (NO DEBER√çA EXISTIR)")
                
                # Eliminar datos de meses incorrectos si este es el √∫ltimo mes que procesamos
                if mes >= mes_num:
                    print(f"  üßπ Limpiando datos incorrectos del mes {mes_num}...")
                    pg_hook.run(f"""
                    DELETE FROM tension_dep_processed 
                    WHERE EXTRACT(MONTH FROM fecha) = {mes_num}
                    AND EXTRACT(YEAR FROM fecha) = 2019
                    """)
        
        # Verificar proporci√≥n de datos correctos
        if total_registros > 0:
            porcentaje_correcto = (registros_mes_correcto / total_registros) * 100
            print(f"üìä Porcentaje de datos del mes correcto: {porcentaje_correcto:.2f}%")
            
            if porcentaje_correcto < 99:
                print(f"‚ö†Ô∏è ADVERTENCIA: Solo el {porcentaje_correcto:.2f}% son datos del mes {mes}")
                return False
            
        return True
    
    except Exception as e:
        print(f"‚ùå Error en verificaci√≥n final: {str(e)}")
        return False

def verificar_datos_procesados_del_mes_correcto(mes, **kwargs):
    """Verifica que los datos procesados correspondan al mes correcto"""
    try:
        # VERIFICACI√ìN DE MESES SIN DATOS
        ti = kwargs.get('ti')
        if ti and ti.xcom_pull(key=f'mes_{mes}_sin_datos_reales'):
            print(f"‚úÖ VERIFICACI√ìN EXITOSA: El mes {mes} fue marcado como sin datos. No se requieren registros.")
            return True  # √âxito para meses sin datos
            
        pg_hook = PostgresHook(postgres_conn_id="postgres_base_prueba")

        # VERIFICACI√ìN ESPECIAL PARA DICIEMBRE
        if mes == 12:
            fecha_inicio = "2019-12-01"
            fecha_fin = "2020-01-01"
            
            # Verificar por fecha expl√≠citamente
            query_fecha = f"""
            SELECT COUNT(*) FROM tension_dep_processed 
            WHERE fecha >= '{fecha_inicio}' AND fecha < '{fecha_fin}'
            """
            count_fecha = pg_hook.get_first(query_fecha)[0]
            
            if count_fecha > 0:
                print(f"‚úÖ VERIFICACI√ìN DICIEMBRE CORRECTA: {count_fecha} registros en el rango de fechas correcto")
                return True
        
        # VERIFICACI√ìN EST√ÅNDAR PARA OTROS MESES
        ano = 2019
        query = f"""
        SELECT COUNT(*) FROM tension_dep_processed 
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = {ano}
        """
        count = pg_hook.get_first(query)[0]
        
        if count > 0:
            print(f"‚úÖ Verificaci√≥n exitosa: {count} registros del mes {mes} a√±o {ano}")
            
            # Mostrar algunos ejemplos para validar
            sample_query = f"""
            SELECT fecha, hora, id_subestacion, dia_semana, tension_servicio
            FROM tension_dep_processed 
            WHERE EXTRACT(MONTH FROM fecha) = {mes}
            AND EXTRACT(YEAR FROM fecha) = {ano}
            LIMIT 5
            """
            samples = pg_hook.get_records(sample_query)
            print("üìä Muestra de registros procesados:")
            for sample in samples:
                print(f"  {sample}")
                
            return True
        else:
            print(f"‚ö†Ô∏è No se encontraron datos del mes {mes} a√±o {ano}")
            return False

    except Exception as e:
        print(f"‚ùå Error en verificaci√≥n: {str(e)}")
        return False


def verificar_si_mes_ya_procesado(mes, ano=2019):
    """
    Verifica si un mes espec√≠fico ya tiene datos procesados en la tabla destino.
    Retorna True si ya hay datos, False si no hay.
    """
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_base_prueba")

        # Construir consulta para verificar existencia de datos
        query = f"""
        SELECT COUNT(*) FROM tension_dep_processed 
        WHERE EXTRACT(MONTH FROM fecha) = {mes}
        AND EXTRACT(YEAR FROM fecha) = {ano}
        """
        count = pg_hook.get_first(query)[0]
        if count > 0:
            print(
                f"‚úÖ El mes {mes} del a√±o {ano} ya tiene {count} registros procesados"
            )

            # Mostrar una muestra para verificar la calidad de los datos
            sample_query = f"""
            SELECT fecha, hora, alimentador, potencia_activa, potencia_reactiva
            FROM tension_dep_processed 
            WHERE EXTRACT(MONTH FROM fecha) = {mes}
            AND EXTRACT(YEAR FROM fecha) = {ano}
            ORDER BY RANDOM()
            LIMIT 2
            """
            samples = pg_hook.get_records(sample_query)
            print("üìä Muestra de registros existentes:")
            for sample in samples:
                print(f"  {sample}")

            return True
        else:
            print(f"‚ö†Ô∏è No se encontraron datos del mes {mes} a√±o {ano}")
            return False
    except Exception as e:
        print(f"‚ùå Error en verificaci√≥n: {str(e)}")
        return False


def verificar_completitud_anual():
    """Verifica la completitud del procesamiento anual del 2019 usando hooks separados"""
    try:
        # Usar PostgresHook con las conexiones correctas
        pg_hook_origen = PostgresHook(postgres_conn_id="postgres_centrosur")
        pg_hook_destino = PostgresHook(postgres_conn_id="postgres_base_prueba")

        # Conteo total de registros en origen para 2019
        total_origen = pg_hook_origen.get_first(
            """
            SELECT COUNT(*) FROM tension_dep 
            WHERE fecha BETWEEN '2019-01-01' AND '2020-01-01'
            """
        )[0]
        
        # Conteo total de registros en destino para 2019
        total_destino = pg_hook_destino.get_first(
            """
            SELECT COUNT(*) FROM tension_dep_processed 
            WHERE fecha BETWEEN '2019-01-01' AND '2020-01-01'
            """
        )[0]
        
        # Conteo por mes en origen
        conteo_origen_por_mes = pg_hook_origen.get_records(
            """
            SELECT EXTRACT(MONTH FROM fecha) AS mes, COUNT(*)
            FROM tension_dep 
            WHERE fecha BETWEEN '2019-01-01' AND '2020-01-01'
            GROUP BY EXTRACT(MONTH FROM fecha)
            ORDER BY mes
            """
        )

        # Conteo por mes en destino
        conteo_destino_por_mes = pg_hook_destino.get_records(
            """
            SELECT EXTRACT(MONTH FROM fecha) AS mes, COUNT(*)
            FROM tension_dep_processed 
            WHERE fecha BETWEEN '2019-01-01' AND '2020-01-01'
            GROUP BY EXTRACT(MONTH FROM fecha)
            ORDER BY mes
            """
        )
        
        # Generar informe
        resultado = "INFORME DE COMPLETITUD DE PROCESAMIENTO ANUAL 2019\n"
        resultado += "=" * 50 + "\n"
        resultado += f"Total registros en origen: {total_origen}\n"
        resultado += f"Total registros en destino: {total_destino}\n"

        if total_origen > 0:
            completitud = (total_destino / total_origen) * 100
            resultado += f"Completitud total: {completitud:.2f}%\n\n"

        resultado += "DETALLE POR MES:\n"
        resultado += "-" * 50 + "\n"
        resultado += "{:<10} {:<15} {:<15} {:<15}\n".format(
            "Mes", "Origen", "Destino", "Completitud"
        )
        resultado += "-" * 50 + "\n"

        # Convertir a diccionarios para facilitar la b√∫squeda
        dict_origen = {int(float(mes)): count for mes, count in conteo_origen_por_mes}
        dict_destino = {int(float(mes)): count for mes, count in conteo_destino_por_mes}

        for mes in range(1, 13):
            origen = dict_origen.get(mes, 0)
            destino = dict_destino.get(mes, 0)

            if origen > 0:
                comp = (destino / origen) * 100
                resultado += "{:<10} {:<15} {:<15} {:<15.2f}%\n".format(
                    calendar.month_name[mes][:3], origen, destino, comp
                )
            else:
                resultado += "{:<10} {:<15} {:<15} {:<15}\n".format(
                    calendar.month_name[mes][:3], origen, destino, "N/A"
                )

        print(resultado)
        return resultado

    except Exception as e:
        error_msg = f"Error al verificar completitud anual: {str(e)}"
        print(error_msg)
        return error_msg


def limpiar_tablas_temporales(**kwargs):
    """Limpia todas las tablas temporales creadas durante el procesamiento"""
    try:
        pg_hook = PostgresHook(postgres_conn_id="postgres_centrosur")
        
        # 1. Recuperar nombres de tablas de trabajo registradas en XComs
        ti = kwargs.get('ti')
        tablas_trabajo = []
        
        if ti:
            for mes in range(1, 13):
                tabla = ti.xcom_pull(key=f'tabla_trabajo_mes_{mes}')
                if tabla:
                    tablas_trabajo.append(tabla)
        
        # 2. Buscar todas las tablas temporales en la base de datos
        query_tablas_temp = """
        SELECT table_name FROM information_schema.tables 
        WHERE table_name LIKE 'tension_dep_work_%' 
           OR table_name LIKE 'tension_dep_temp_%'
           OR table_name LIKE 'tension_dep_prev_%'
           OR table_name LIKE 'tension_dep_backup_%'
        """
        
        tablas_db = pg_hook.get_records(query_tablas_temp)
        tablas_a_eliminar = set(tablas_trabajo)  # Uso set para evitar duplicados
        
        for tabla in tablas_db:
            nombre_tabla = tabla[0]
            # Proteger las tablas cr√≠ticas 
            if nombre_tabla not in ['tension_dep', 'tension_dep_original', 'tension_dep_processed']:
                tablas_a_eliminar.add(nombre_tabla)
        
        # 3. Eliminar todas las tablas identificadas
        count = 0
        for tabla in tablas_a_eliminar:
            try:
                pg_hook.run(f"DROP TABLE IF EXISTS {tabla}")
                print(f"üóëÔ∏è Eliminada tabla temporal: {tabla}")
                count += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Error al eliminar tabla {tabla}: {str(e)}")
        
        return f"Limpiadas {count} tablas temporales"
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error en limpieza de tablas: {str(e)}")
        return f"Error en limpieza: {str(e)}"


# Configurar el DAG para procesar m√∫ltiples meses en secuencia con verificaci√≥n
with dag:
    verificar_tabla_original = PythonOperator(
        task_id="verificar_y_restaurar_tabla_original",
        python_callable=verificar_y_restaurar_tabla_original_al_inicio,
    )
    verificar_disponibilidad = PythonOperator(
    task_id="verificar_disponibilidad_datos",
    python_callable=verificar_disponibilidad_datos_por_mes,
    )
    setup_connections = PythonOperator(
        task_id="setup_connections",
        python_callable=create_postgres_connections,
    )

    verificar_proxy = PythonOperator(
        task_id="verificar_proxy",
        python_callable=verificar_proxy_disponible,
    )

    # Task Group para procesar Enero (Mes 1)
    with TaskGroup(group_id="procesar_enero") as grupo_enero:
        verificar_enero = PythonOperator(
            task_id="verificar_si_enero_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 1},
        )

        # Branch operator que decide entre dos caminos completamente diferentes
        branch_enero = BranchPythonOperator(
            task_id="branch_enero",
            python_callable=lambda ti: (
                "procesar_enero.camino_procesamiento.procesar_mes_1"
                if not ti.xcom_pull(
                    task_ids="procesar_enero.verificar_si_enero_ya_procesado"
                )
                else "procesar_enero.skip_y_verificar.skip_enero"
            ),
            trigger_rule="all_done",
        )
    #ojo
        # Subcamino para procesamiento (incluye espera)
        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_1 = PythonOperator(
                task_id="procesar_mes_1",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 1},
            )
            esperar_verificar_1 = PythonOperator(
                task_id="esperar_verificar_1",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 1, "tiempo_espera_minutos": 12},
            )

            verificar_enero_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 1},
            )

            # Secuencia dentro del camino de procesamiento
            procesar_mes_1 >> esperar_verificar_1 >> verificar_enero_completado

        # Subcamino para saltar (sin espera)
        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_enero = DummyOperator(
                task_id="skip_enero",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 1 ya procesado, verificaci√≥n confirmada"
                ),
            )

            # Secuencia dentro del camino de skip
            skip_enero >> verificar_skip

        # Secuencia principal del grupo
        verificar_enero >> branch_enero >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Febrero (Mes 2)
    with TaskGroup(group_id="procesar_febrero") as grupo_febrero:
        verificar_febrero = PythonOperator(
            task_id="verificar_si_febrero_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 2},
        )

        branch_febrero = BranchPythonOperator(
         task_id="branch_febrero",
        python_callable=decidir_ruta_mes,
        op_kwargs={
             "mes": 2,
            "nombre_mes": "febrero"
        },
        trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_2 = PythonOperator(
                task_id="procesar_mes_2",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 2},
            )
            esperar_verificar_2 = PythonOperator(
                task_id="esperar_verificar_2",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 2, "tiempo_espera_minutos": 12},
            )

            verificar_febrero_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 2},
            )

            procesar_mes_2 >> esperar_verificar_2 >> verificar_febrero_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_febrero = DummyOperator(
                task_id="skip_febrero",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 2 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_febrero >> verificar_skip

        verificar_febrero >> branch_febrero >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Marzo (Mes 3)
    with TaskGroup(group_id="procesar_marzo") as grupo_marzo:
        verificar_marzo = PythonOperator(
            task_id="verificar_si_marzo_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 3},
        )

        branch_marzo = BranchPythonOperator(
            task_id="branch_marzo",
            python_callable=lambda ti: (
                "procesar_marzo.camino_procesamiento.procesar_mes_3"
                if not ti.xcom_pull(
                    task_ids="procesar_marzo.verificar_si_marzo_ya_procesado"
                )
                else "procesar_marzo.skip_y_verificar.skip_marzo"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_3 = PythonOperator(
                task_id="procesar_mes_3",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 3},
            )
            esperar_verificar_3 = PythonOperator(
                task_id="esperar_verificar_3",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 3, "tiempo_espera_minutos": 12},
            )

            verificar_marzo_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 3},
            )

            procesar_mes_3 >> esperar_verificar_3 >> verificar_marzo_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_marzo = DummyOperator(
                task_id="skip_marzo",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 3 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_marzo >> verificar_skip

        verificar_marzo >> branch_marzo >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Abril (Mes 4)
    with TaskGroup(group_id="procesar_abril") as grupo_abril:
        verificar_abril = PythonOperator(
            task_id="verificar_si_abril_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 4},
        )

        branch_abril = BranchPythonOperator(
            task_id="branch_abril",
            python_callable=lambda ti: (
                "procesar_abril.camino_procesamiento.procesar_mes_4"
                if not ti.xcom_pull(
                    task_ids="procesar_abril.verificar_si_abril_ya_procesado"
                )
                else "procesar_abril.skip_y_verificar.skip_abril"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_4 = PythonOperator(
                task_id="procesar_mes_4",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 4},
            )
            esperar_verificar_4 = PythonOperator(
                task_id="esperar_verificar_4",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 4, "tiempo_espera_minutos": 12},
            )
            verificar_abril_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 4},
            )

            procesar_mes_4 >> esperar_verificar_4 >> verificar_abril_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_abril = DummyOperator(
                task_id="skip_abril",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 4 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_abril >> verificar_skip

        verificar_abril >> branch_abril >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Mayo (Mes 5)
    with TaskGroup(group_id="procesar_mayo") as grupo_mayo:
        verificar_mayo = PythonOperator(
            task_id="verificar_si_mayo_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 5},
        )

        branch_mayo = BranchPythonOperator(
            task_id="branch_mayo",
            python_callable=lambda ti: (
                "procesar_mayo.camino_procesamiento.procesar_mes_5"
                if not ti.xcom_pull(
                    task_ids="procesar_mayo.verificar_si_mayo_ya_procesado"
                )
                else "procesar_mayo.skip_y_verificar.skip_mayo"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_5 = PythonOperator(
                task_id="procesar_mes_5",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 5},
            )
            esperar_verificar_5 = PythonOperator(
                task_id="esperar_verificar_5",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 5, "tiempo_espera_minutos": 12},
            )

            verificar_mayo_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 5},
            )

            procesar_mes_5 >> esperar_verificar_5 >> verificar_mayo_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_mayo = DummyOperator(
                task_id="skip_mayo",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 5 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_mayo >> verificar_skip

        verificar_mayo >> branch_mayo >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Junio (Mes 6)
    with TaskGroup(group_id="procesar_junio") as grupo_junio:
        verificar_junio = PythonOperator(
            task_id="verificar_si_junio_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 6},
        )

        branch_junio = BranchPythonOperator(
            task_id="branch_junio",
            python_callable=lambda ti: (
                "procesar_junio.camino_procesamiento.procesar_mes_6"
                if not ti.xcom_pull(
                    task_ids="procesar_junio.verificar_si_junio_ya_procesado"
                )
                else "procesar_junio.skip_y_verificar.skip_junio"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_6 = PythonOperator(
                task_id="procesar_mes_6",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 6},
            )
            esperar_verificar_6 = PythonOperator(
                task_id="esperar_verificar_6",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 6, "tiempo_espera_minutos": 12},
            )
            verificar_junio_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 6},
            )

            procesar_mes_6 >> esperar_verificar_6 >> verificar_junio_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_junio = DummyOperator(
                task_id="skip_junio",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 6 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_junio >> verificar_skip

        verificar_junio >> branch_junio >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Julio (Mes 7)
    with TaskGroup(group_id="procesar_julio") as grupo_julio:
        verificar_julio = PythonOperator(
            task_id="verificar_si_julio_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 7},
        )

        branch_julio = BranchPythonOperator(
            task_id="branch_julio",
            python_callable=lambda ti: (
                "procesar_julio.camino_procesamiento.procesar_mes_7"
                if not ti.xcom_pull(
                    task_ids="procesar_julio.verificar_si_julio_ya_procesado"
                )
                else "procesar_julio.skip_y_verificar.skip_julio"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_7 = PythonOperator(
                task_id="procesar_mes_7",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 7},
            )
            esperar_verificar_7 = PythonOperator(
                task_id="esperar_verificar_7",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 7, "tiempo_espera_minutos": 12},
            )

            verificar_julio_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 7},
            )

            procesar_mes_7 >> esperar_verificar_7 >> verificar_julio_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_julio = DummyOperator(
                task_id="skip_julio",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 7 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_julio >> verificar_skip

        verificar_julio >> branch_julio >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Agosto (Mes 8)
    with TaskGroup(group_id="procesar_agosto") as grupo_agosto:
        verificar_agosto = PythonOperator(
            task_id="verificar_si_agosto_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 8},
        )

        branch_agosto = BranchPythonOperator(
            task_id="branch_agosto",
            python_callable=lambda ti: (
                "procesar_agosto.camino_procesamiento.procesar_mes_8"
                if not ti.xcom_pull(
                    task_ids="procesar_agosto.verificar_si_agosto_ya_procesado"
                )
                else "procesar_agosto.skip_y_verificar.skip_agosto"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_8 = PythonOperator(
                task_id="procesar_mes_8",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 8},
            )
            esperar_verificar_8 = PythonOperator(
                task_id="esperar_verificar_8",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 8, "tiempo_espera_minutos": 12},
            )

            verificar_agosto_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 8},
            )

            procesar_mes_8 >> esperar_verificar_8 >> verificar_agosto_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_agosto = DummyOperator(
                task_id="skip_agosto",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 8 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_agosto >> verificar_skip

        verificar_agosto >> branch_agosto >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Septiembre (Mes 9)
    with TaskGroup(group_id="procesar_septiembre") as grupo_septiembre:
        verificar_septiembre = PythonOperator(
            task_id="verificar_si_septiembre_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 9},
        )

        branch_septiembre = BranchPythonOperator(
            task_id="branch_septiembre",
            python_callable=lambda ti: (
                "procesar_septiembre.camino_procesamiento.procesar_mes_9"
                if not ti.xcom_pull(
                    task_ids="procesar_septiembre.verificar_si_septiembre_ya_procesado"
                )
                else "procesar_septiembre.skip_y_verificar.skip_septiembre"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_9 = PythonOperator(
                task_id="procesar_mes_9",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 9},
            )
            esperar_verificar_9 = PythonOperator(
                task_id="esperar_verificar_9",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 9, "tiempo_espera_minutos": 12},
            )
            verificar_septiembre_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 9},
            )

            procesar_mes_9 >> esperar_verificar_9 >> verificar_septiembre_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_septiembre = DummyOperator(
                task_id="skip_septiembre",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 9 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_septiembre >> verificar_skip

        (
            verificar_septiembre
            >> branch_septiembre
            >> [camino_procesamiento, skip_y_verificar]
        )

    # Task Group para procesar Octubre (Mes 10)
    with TaskGroup(group_id="procesar_octubre") as grupo_octubre:
        verificar_octubre = PythonOperator(
            task_id="verificar_si_octubre_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 10},
            provide_context=True, 
        )

        branch_octubre = BranchPythonOperator(
            task_id="branch_octubre",
            python_callable=lambda ti: (
                "procesar_octubre.camino_procesamiento.procesar_mes_10"
                if not ti.xcom_pull(
                    task_ids="procesar_octubre.verificar_si_octubre_ya_procesado"
                )
                else "procesar_octubre.skip_y_verificar.skip_octubre"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_10 = PythonOperator(
                task_id="procesar_mes_10",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 10},
            )
            esperar_verificar_10 = PythonOperator(
                task_id="esperar_verificar_10",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 10, "tiempo_espera_minutos": 12},
            )
            verificar_octubre_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 10},
                provide_context=True,  # A√ëADIDO para pasar kwargs
            )

            procesar_mes_10 >> esperar_verificar_10 >> verificar_octubre_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_octubre = DummyOperator(
                task_id="skip_octubre",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 10 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_octubre >> verificar_skip

        verificar_octubre >> branch_octubre >> [camino_procesamiento, skip_y_verificar]

    # Task Group para procesar Noviembre (Mes 11)
    with TaskGroup(group_id="procesar_noviembre") as grupo_noviembre:
        verificar_noviembre = PythonOperator(
            task_id="verificar_si_noviembre_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 11},
        )

        branch_noviembre = BranchPythonOperator(
            task_id="branch_noviembre",
            python_callable=lambda ti: (
                "procesar_noviembre.camino_procesamiento.procesar_mes_11"
                if not ti.xcom_pull(
                    task_ids="procesar_noviembre.verificar_si_noviembre_ya_procesado"
                )
                else "procesar_noviembre.skip_y_verificar.skip_noviembre"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_11 = PythonOperator(
                task_id="procesar_mes_11",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 11},
            )

            esperar_verificar_11 = PythonOperator(
                task_id="esperar_verificar_11",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 11, "tiempo_espera_minutos": 12},
            )
            verificar_noviembre_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 11},
            )

            procesar_mes_11 >> esperar_verificar_11 >> verificar_noviembre_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_noviembre = DummyOperator(
                task_id="skip_noviembre",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 11 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_noviembre >> verificar_skip

        (
            verificar_noviembre
            >> branch_noviembre
            >> [camino_procesamiento, skip_y_verificar]
        )

    # Task Group para procesar Diciembre (Mes 12)
    with TaskGroup(group_id="procesar_diciembre") as grupo_diciembre:
        verificar_diciembre = PythonOperator(
            task_id="verificar_si_diciembre_ya_procesado",
            python_callable=verificar_si_mes_ya_procesado,
            op_kwargs={"mes": 12},
            provide_context=True,
        )

        branch_diciembre = BranchPythonOperator(
            task_id="branch_diciembre",
            python_callable=lambda ti: (
                "procesar_diciembre.camino_procesamiento.procesar_mes_12"
                if not ti.xcom_pull(
                    task_ids="procesar_diciembre.verificar_si_diciembre_ya_procesado"
                )
                else "procesar_diciembre.skip_y_verificar.skip_diciembre"
            ),
            trigger_rule="all_done",
        )

        with TaskGroup(group_id="camino_procesamiento") as camino_procesamiento:
            procesar_mes_12 = PythonOperator(
                task_id="procesar_mes_12",
                python_callable=procesar_y_restaurar_mes,
                op_kwargs={"mes": 12},
            )
            esperar_verificar_12 = PythonOperator(
                task_id="esperar_verificar_12",
                python_callable=esperar_verificar_y_finalizar_mes,
                op_kwargs={"mes": 12, "tiempo_espera_minutos": 12},
            )
            verificar_diciembre_completado = PythonOperator(
                task_id="verificar_resultados",
                python_callable=verificar_datos_procesados_del_mes_correcto,
                op_kwargs={"mes": 12},
            )

            procesar_mes_12 >> esperar_verificar_12 >> verificar_diciembre_completado

        with TaskGroup(group_id="skip_y_verificar") as skip_y_verificar:
            skip_diciembre = DummyOperator(
                task_id="skip_diciembre",
            )

            verificar_skip = PythonOperator(
                task_id="verificar_skip",
                python_callable=lambda ti: print(
                    f"‚úÖ Mes 12 ya procesado, verificaci√≥n confirmada"
                ),
            )

            skip_diciembre >> verificar_skip

        (
            verificar_diciembre
            >> branch_diciembre
            >> [camino_procesamiento, skip_y_verificar]
        )
    
    with TaskGroup(group_id="verificar_datos_diciembre") as verificar_dic:
        chequear_si_hay_datos = PythonOperator(
            task_id="verificar_si_hay_datos_diciembre",
            python_callable=verificar_existencia_datos_fuente,
            op_kwargs={"mes": 12},
        )

        mensaje_advirtiendo = PythonOperator(
            task_id="mensaje_informativo",
            python_callable=lambda ti: print(
                f"""
        ‚ö†Ô∏è ATENCI√ìN: {'NO hay' if not ti.xcom_pull(task_ids='verificar_datos_diciembre.verificar_si_hay_datos_diciembre') else 'Existen'} datos para el mes 12 (Diciembre) 2019.
        {'Esto no es un error del DAG, es una caracter√≠stica de los datos de origen.' if not ti.xcom_pull(task_ids='verificar_datos_diciembre.verificar_si_hay_datos_diciembre') else 'Los datos se han procesado correctamente.'} 
        El DAG ha completado el procesamiento de todos los meses que tienen datos disponibles.
        """
            ),
            provide_context=True,
        )

        chequear_si_hay_datos >> mensaje_advirtiendo


    # Tarea para verificar completitud del a√±o
    verificar_completitud = PythonOperator(
        task_id="verificar_completitud_anual",
        python_callable=verificar_completitud_anual,
    )

    # Tarea final para restaurar la tabla original
    restaurar = PythonOperator(
        task_id="restaurar_estado_original",
        python_callable=restaurar_estado_original_completo,  # Nueva funci√≥n
        trigger_rule="all_done",
    )

    limpiar_tmp = PythonOperator(
         task_id="limpiar_tablas_temporales",
        python_callable=limpiar_tablas_temporales,  # Nueva funci√≥n
        trigger_rule="all_done",
    )

    # Definir la secuencia general del DAG
    (
        verificar_tabla_original
        >> setup_connections
        >> verificar_disponibilidad
        >> verificar_proxy
        >> grupo_enero
        >> grupo_febrero
        >> grupo_marzo
        >> grupo_abril
        >> grupo_mayo
        >> grupo_junio
        >> grupo_julio
        >> grupo_agosto
        >> grupo_septiembre
        >> grupo_octubre
        >> grupo_noviembre
        >> grupo_diciembre
        >> verificar_dic
        >> verificar_completitud
        >> limpiar_tmp
        >> restaurar
    )
